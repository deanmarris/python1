{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Hyperparameter_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "o-Q5Nfzd6lSE",
        "GSXsVeao7E18",
        "ued0s2OFFPp8",
        "rlJo0tqZB48x",
        "K1TXXiVnkojb",
        "To7DBE72ToBB",
        "v4EdbkeRUXlL",
        "HcY_7AY-WF3x",
        "jOOVlxp3XeuA",
        "1XJW7G9aYDMg",
        "5V5JsZztaahv",
        "w1iI6ts2a4EK",
        "Qul0TkT6ewvK",
        "0nd2B8VNh0OI",
        "9f2IHtLWim4Y",
        "p4doPgkijJ_0",
        "Cv4IRopolh3r",
        "XwifHLlXmPl7",
        "iUcQPy_in8fY",
        "1HI7rvfZqtcQ",
        "wOkjiSD4tyBh",
        "WRgGotqVvA3C",
        "b-TLMPdyx9bS",
        "OBa2BEn4yNyY",
        "5Dz7QJ1Cypqz",
        "6WLS5CndznRK",
        "fh45Vj3gg1Tu",
        "7j-nGgjTM7gz",
        "YydibsV2SQ-t",
        "0Ya_sdrJTTYh",
        "8s8maPDtTusO",
        "Iu3iXnyp95OJ",
        "hA8vhA3zDrOJ",
        "KDKcK-KKGFAc",
        "UCXfE3_RILLM",
        "1i8LwQy0IycL",
        "a6tHO3SwVbHs",
        "iJaQrXwuf1L0",
        "7lAwDBUCil09",
        "oJrgrHjUi16E",
        "6wNzI8GNjLRc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanmarris/python1/blob/master/05_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m7ZhNdMERaG"
      },
      "source": [
        "# Hyperparameter Tuning to Improve Model Performance\n",
        "\n",
        "- Author: Amy Zhuang\n",
        "- Last Updated: May 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Q5Nfzd6lSE"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7wM9m8J60Ze"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout\n",
        "from keras.activations import relu, sigmoid\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from hyperopt import tpe\n",
        "from hyperopt import STATUS_OK\n",
        "from hyperopt import Trials\n",
        "from hyperopt import hp\n",
        "from hyperopt import fmin\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSXsVeao7E18"
      },
      "source": [
        "## Readin Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHv1MJmL62zR"
      },
      "source": [
        "from sklearn import datasets\n",
        "data = datasets.load_breast_cancer()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JaM6-E3A4dZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b4fb73-e5ab-4473-95b4-2ca970a1f294"
      },
      "source": [
        "data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
              " 'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv',\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p8WoyR-9PMl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d9a619fb-8c24-4d37-b695-e8412c1f6dc6"
      },
      "source": [
        "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "3        11.42         20.38  ...                  0.17300       0\n",
              "4        20.29         14.34  ...                  0.07678       0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXODE91N-MDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b007db-5c61-4649-adc8-f3ba63307078"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLmMwLJv_HS1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "e7c36769-b343-4a77-a0b8-27408f8e1739"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.627417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.483918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       mean radius  mean texture  ...  worst fractal dimension      target\n",
              "count   569.000000    569.000000  ...               569.000000  569.000000\n",
              "mean     14.127292     19.289649  ...                 0.083946    0.627417\n",
              "std       3.524049      4.301036  ...                 0.018061    0.483918\n",
              "min       6.981000      9.710000  ...                 0.055040    0.000000\n",
              "25%      11.700000     16.170000  ...                 0.071460    0.000000\n",
              "50%      13.370000     18.840000  ...                 0.080040    1.000000\n",
              "75%      15.780000     21.800000  ...                 0.092080    1.000000\n",
              "max      28.110000     39.280000  ...                 0.207500    1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt5aNd2o_Rky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2ec7b1-6d6d-4ab5-e245-6186aec8477a"
      },
      "source": [
        "df['target'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4YxUckqBlXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91f42b8-dee1-458b-e93b-710655549036"
      },
      "source": [
        "df['target'].value_counts(normalize=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.627417\n",
              "0    0.372583\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ued0s2OFFPp8"
      },
      "source": [
        "## Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJpPtR6qHE1p"
      },
      "source": [
        "X_features = df[df.columns.difference(['target'])]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z4Q9cqhELby"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = pd.DataFrame(sc.fit_transform(X_features),index=X_features.index,columns=X_features.columns)\n",
        "# Note: For the datasets with outliers, standardize using Robust Scaler"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUbgGHeeqNJb"
      },
      "source": [
        "Add the describe after standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjtFeZRDFW4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "c45235e1-61a2-455f-f7d9-6166520420d0"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-8.291551e-16</td>\n",
              "      <td>-3.921877e-16</td>\n",
              "      <td>-2.739461e-16</td>\n",
              "      <td>7.917900e-16</td>\n",
              "      <td>-3.366766e-16</td>\n",
              "      <td>-8.799835e-16</td>\n",
              "      <td>-1.120369e-15</td>\n",
              "      <td>9.732500e-16</td>\n",
              "      <td>-4.421380e-16</td>\n",
              "      <td>-1.453631e-15</td>\n",
              "      <td>-7.078891e-16</td>\n",
              "      <td>-3.162867e-15</td>\n",
              "      <td>6.132177e-15</td>\n",
              "      <td>-1.971670e-15</td>\n",
              "      <td>-6.530609e-15</td>\n",
              "      <td>1.773674e-15</td>\n",
              "      <td>-9.076415e-16</td>\n",
              "      <td>-7.541809e-16</td>\n",
              "      <td>-3.108234e-16</td>\n",
              "      <td>-8.853492e-16</td>\n",
              "      <td>5.049661e-16</td>\n",
              "      <td>-2.174788e-15</td>\n",
              "      <td>-1.412656e-16</td>\n",
              "      <td>6.856456e-16</td>\n",
              "      <td>2.575171e-15</td>\n",
              "      <td>-1.198026e-15</td>\n",
              "      <td>-2.333224e-15</td>\n",
              "      <td>-5.213170e-15</td>\n",
              "      <td>-2.289567e-15</td>\n",
              "      <td>1.763674e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-7.378291e-01</td>\n",
              "      <td>-1.298098e+00</td>\n",
              "      <td>-1.913447e+00</td>\n",
              "      <td>-1.057501e+00</td>\n",
              "      <td>-1.096968e+00</td>\n",
              "      <td>-1.454443e+00</td>\n",
              "      <td>-1.610136e+00</td>\n",
              "      <td>-1.261820e+00</td>\n",
              "      <td>-1.114873e+00</td>\n",
              "      <td>-1.819865e+00</td>\n",
              "      <td>-1.984504e+00</td>\n",
              "      <td>-2.029648e+00</td>\n",
              "      <td>-3.112085e+00</td>\n",
              "      <td>-2.744117e+00</td>\n",
              "      <td>-2.229249e+00</td>\n",
              "      <td>-1.044049e+00</td>\n",
              "      <td>-1.059924e+00</td>\n",
              "      <td>-1.776065e+00</td>\n",
              "      <td>-1.532890e+00</td>\n",
              "      <td>-1.554264e+00</td>\n",
              "      <td>-1.222423e+00</td>\n",
              "      <td>-1.443878e+00</td>\n",
              "      <td>-1.745063e+00</td>\n",
              "      <td>-1.305831e+00</td>\n",
              "      <td>-1.601839e+00</td>\n",
              "      <td>-1.693361e+00</td>\n",
              "      <td>-1.726901e+00</td>\n",
              "      <td>-2.682695e+00</td>\n",
              "      <td>-2.160960e+00</td>\n",
              "      <td>-2.223994e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-4.947542e-01</td>\n",
              "      <td>-6.929263e-01</td>\n",
              "      <td>-6.744900e-01</td>\n",
              "      <td>-5.571612e-01</td>\n",
              "      <td>-5.851185e-01</td>\n",
              "      <td>-6.671955e-01</td>\n",
              "      <td>-7.470860e-01</td>\n",
              "      <td>-7.379438e-01</td>\n",
              "      <td>-7.437479e-01</td>\n",
              "      <td>-7.226392e-01</td>\n",
              "      <td>-6.919555e-01</td>\n",
              "      <td>-6.893853e-01</td>\n",
              "      <td>-7.109628e-01</td>\n",
              "      <td>-7.032397e-01</td>\n",
              "      <td>-7.259631e-01</td>\n",
              "      <td>-6.237679e-01</td>\n",
              "      <td>-6.235706e-01</td>\n",
              "      <td>-6.240183e-01</td>\n",
              "      <td>-6.516807e-01</td>\n",
              "      <td>-6.948092e-01</td>\n",
              "      <td>-6.421359e-01</td>\n",
              "      <td>-6.810833e-01</td>\n",
              "      <td>-7.563999e-01</td>\n",
              "      <td>-7.565142e-01</td>\n",
              "      <td>-6.919118e-01</td>\n",
              "      <td>-6.895783e-01</td>\n",
              "      <td>-6.749213e-01</td>\n",
              "      <td>-6.912304e-01</td>\n",
              "      <td>-6.418637e-01</td>\n",
              "      <td>-7.486293e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.477828e-01</td>\n",
              "      <td>-2.810204e-01</td>\n",
              "      <td>-1.404958e-01</td>\n",
              "      <td>-1.990654e-01</td>\n",
              "      <td>-2.299405e-01</td>\n",
              "      <td>-2.951869e-01</td>\n",
              "      <td>-2.219405e-01</td>\n",
              "      <td>-3.977212e-01</td>\n",
              "      <td>-3.422399e-01</td>\n",
              "      <td>-1.782793e-01</td>\n",
              "      <td>-2.359800e-01</td>\n",
              "      <td>-2.150816e-01</td>\n",
              "      <td>-3.489108e-02</td>\n",
              "      <td>-7.162650e-02</td>\n",
              "      <td>-1.046362e-01</td>\n",
              "      <td>-2.866520e-01</td>\n",
              "      <td>-2.922452e-01</td>\n",
              "      <td>-2.203352e-01</td>\n",
              "      <td>-2.194304e-01</td>\n",
              "      <td>-1.974976e-01</td>\n",
              "      <td>-3.411812e-01</td>\n",
              "      <td>-2.695009e-01</td>\n",
              "      <td>-2.234689e-01</td>\n",
              "      <td>-2.182321e-01</td>\n",
              "      <td>-2.164441e-01</td>\n",
              "      <td>-2.859802e-01</td>\n",
              "      <td>-2.690395e-01</td>\n",
              "      <td>-4.684277e-02</td>\n",
              "      <td>-1.274095e-01</td>\n",
              "      <td>-4.351564e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.067726e-01</td>\n",
              "      <td>3.896541e-01</td>\n",
              "      <td>4.726567e-01</td>\n",
              "      <td>3.367521e-01</td>\n",
              "      <td>2.886421e-01</td>\n",
              "      <td>3.635073e-01</td>\n",
              "      <td>4.938569e-01</td>\n",
              "      <td>6.469351e-01</td>\n",
              "      <td>5.260619e-01</td>\n",
              "      <td>4.709834e-01</td>\n",
              "      <td>4.996769e-01</td>\n",
              "      <td>4.693926e-01</td>\n",
              "      <td>6.361990e-01</td>\n",
              "      <td>5.307792e-01</td>\n",
              "      <td>5.841756e-01</td>\n",
              "      <td>2.430307e-01</td>\n",
              "      <td>2.660996e-01</td>\n",
              "      <td>3.683553e-01</td>\n",
              "      <td>3.556925e-01</td>\n",
              "      <td>4.665523e-01</td>\n",
              "      <td>3.575891e-01</td>\n",
              "      <td>5.396688e-01</td>\n",
              "      <td>7.125100e-01</td>\n",
              "      <td>5.311411e-01</td>\n",
              "      <td>4.507624e-01</td>\n",
              "      <td>5.402790e-01</td>\n",
              "      <td>5.220158e-01</td>\n",
              "      <td>5.975448e-01</td>\n",
              "      <td>4.501382e-01</td>\n",
              "      <td>6.583411e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.104184e+01</td>\n",
              "      <td>6.143482e+00</td>\n",
              "      <td>6.649601e+00</td>\n",
              "      <td>1.207268e+01</td>\n",
              "      <td>9.851593e+00</td>\n",
              "      <td>5.250529e+00</td>\n",
              "      <td>4.568425e+00</td>\n",
              "      <td>3.927930e+00</td>\n",
              "      <td>4.243589e+00</td>\n",
              "      <td>4.910919e+00</td>\n",
              "      <td>3.976130e+00</td>\n",
              "      <td>3.971288e+00</td>\n",
              "      <td>4.770911e+00</td>\n",
              "      <td>4.484751e+00</td>\n",
              "      <td>4.651889e+00</td>\n",
              "      <td>9.461986e+00</td>\n",
              "      <td>8.906909e+00</td>\n",
              "      <td>8.029999e+00</td>\n",
              "      <td>7.071917e+00</td>\n",
              "      <td>6.655279e+00</td>\n",
              "      <td>5.930172e+00</td>\n",
              "      <td>5.112877e+00</td>\n",
              "      <td>2.685877e+00</td>\n",
              "      <td>4.700669e+00</td>\n",
              "      <td>6.846856e+00</td>\n",
              "      <td>4.287337e+00</td>\n",
              "      <td>4.094189e+00</td>\n",
              "      <td>3.955374e+00</td>\n",
              "      <td>6.046041e+00</td>\n",
              "      <td>3.885905e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         area error  compactness error  ...  worst symmetry  worst texture\n",
              "count  5.690000e+02       5.690000e+02  ...    5.690000e+02   5.690000e+02\n",
              "mean  -8.291551e-16      -3.921877e-16  ...   -2.289567e-15   1.763674e-15\n",
              "std    1.000880e+00       1.000880e+00  ...    1.000880e+00   1.000880e+00\n",
              "min   -7.378291e-01      -1.298098e+00  ...   -2.160960e+00  -2.223994e+00\n",
              "25%   -4.947542e-01      -6.929263e-01  ...   -6.418637e-01  -7.486293e-01\n",
              "50%   -3.477828e-01      -2.810204e-01  ...   -1.274095e-01  -4.351564e-02\n",
              "75%    1.067726e-01       3.896541e-01  ...    4.501382e-01   6.583411e-01\n",
              "max    1.104184e+01       6.143482e+00  ...    6.046041e+00   3.885905e+00\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlJo0tqZB48x"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqePXiEiBh5_"
      },
      "source": [
        "y = df['target']"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28qltqmEiH3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7BfXpphHBUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c9e037-ce58-4236-b49a-da31cd29716a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Bf7N7wHHaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc20684-a62a-4bd8-9665-5cffc7deaaed"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HT9p6cHHLCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b84eb65-a3f7-4255-bf41-6199ab737b58"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESZ-zj9uHPms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ec7b97-7400-41ae-e72a-27b01f13fa3a"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1TXXiVnkojb"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To7DBE72ToBB"
      },
      "source": [
        "## Check Default Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnNojWITca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50aaf03f-d140-456e-9e43-9f131419fc02"
      },
      "source": [
        "xgboost = XGBClassifier(seed=0)\n",
        "from pprint import pprint\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(xgboost.get_params())\n",
        "\n",
        "# Reference: XGBoost documentation at https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "# base_score: The initial prediction score of all instances, For sufficient number of iterations, changing this value will not have too much effect.\n",
        "# booster: Which booster to use. Can be gbtree, gblinear or dart; gbtree and dart use tree based models while gblinear uses linear functions.\n",
        "# colsample_bylevel: is the subsample ratio of columns for each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree.\n",
        "# colsample_bynode: is the subsample ratio of columns for each node (split). Subsampling occurs once every time a new split is evaluated. Columns are subsampled from the set of columns chosen for the current level.\n",
        "# colsample_bytree: is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
        "# gamma: Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
        "# learning_rate/eta: Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
        "# max_delta_step: Maximum delta step we allow each leaf output to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative. Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced. Set it to value of 1-10 might help control the update.\n",
        "# max_depth: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. \n",
        "# min_child_weight: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be.\n",
        "# missing: Handles missing values\n",
        "# n_estimators: Number of trees\n",
        "# n_jobs: parallel processing when it equals -1\n",
        "# nthread: Number of parallel threads used to run XGBoost. When choosing it, please keep thread contention and hyperthreading in mind.\n",
        "# objective: When used with binary classification, the objective should be binary:logistic or similar functions that work on probability. When used with multi-class classification, objective should be multi:softprob instead of multi:softmax, as the latter doesn’t output probability. \n",
        "# random_state: seed to get reproducible results\n",
        "# reg_alpha: L1 regularization term on weights. Increasing this value will make model more conservative.\n",
        "# reg_lambda: L2 regularization term on weights. Increasing this value will make model more conservative.\n",
        "# scale_pos_weight: Control the balance of positive and negative weights, useful for unbalanced classes.\n",
        "# silent: control verbosity\n",
        "# subsample: Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting.\n",
        "# verbosity: Verbosity of printing messages. Valid values of 0 (silent), 1 (warning), 2 (info), and 3 (debug)."
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 1,\n",
            " 'gamma': 0,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 3,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': None,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'binary:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 0,\n",
            " 'reg_lambda': 1,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': 0,\n",
            " 'silent': None,\n",
            " 'subsample': 1,\n",
            " 'verbosity': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4EdbkeRUXlL"
      },
      "source": [
        "## Grid Search Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIGtxuyrTcYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5da315-91b3-4a99-96a2-5bfc83621aa9"
      },
      "source": [
        "param_grid = { \"learning_rate\"    : [0.001, 0.01, 0.1] ,\n",
        " \"max_depth\"        : [ 3,  6, 12],\n",
        " \"min_child_weight\" : [ 1, 5, 9 ],\n",
        "# Gamma specifies the minimum loss reduction required to make a split.\n",
        " \"gamma\"  : [0, 0.1, 0.3],\n",
        "# Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
        " \"colsample_bytree\" : [ 0.3, 0.5 , 0.8 ]}\n",
        "param_grid"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': [0.3, 0.5, 0.8],\n",
              " 'gamma': [0, 0.1, 0.3],\n",
              " 'learning_rate': [0.001, 0.01, 0.1],\n",
              " 'max_depth': [3, 6, 12],\n",
              " 'min_child_weight': [1, 5, 9]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiPdTh6dTcTX"
      },
      "source": [
        "scoring = ['recall']"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9dk1V8JTcN5"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf5wMPj2TcLC"
      },
      "source": [
        "grid_search = GridSearchCV(xgboost, param_grid, scoring=scoring, refit='recall', n_jobs=-1, cv=kfold, verbose=1)\n",
        "# scoring: Strategy to evaluate the performance of the cross-validated model on the test set.\n",
        "# refit: Refit an estimator using the best found parameters on the whole dataset."
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nUsoarmTcG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5db9e3-87f7-462a-b005-6385c840264a"
      },
      "source": [
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "# 3*3*3*3*3 = 243"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=-1)]: Done 726 out of 729 | elapsed:   32.2s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done 729 out of 729 | elapsed:   32.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYPBSDMTcDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c8a463-7feb-43fd-9719-03092acbce71"
      },
      "source": [
        "grid_result"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:l...\n",
              "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=0, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
              "                         'gamma': [0, 0.1, 0.3],\n",
              "                         'learning_rate': [0.001, 0.01, 0.1],\n",
              "                         'max_depth': [3, 6, 12],\n",
              "                         'min_child_weight': [1, 5, 9]},\n",
              "             pre_dispatch='2*n_jobs', refit='recall', return_train_score=False,\n",
              "             scoring=['recall'], verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvTeu8DzTb_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc1bd28-2361-4a57-e411-3362f8583b8e"
      },
      "source": [
        "grid_result.cv_results_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.15311384, 0.05463465, 0.04918742, 0.08129748, 0.06143117,\n",
              "        0.05199456, 0.07483872, 0.05670071, 0.0494477 , 0.05939468,\n",
              "        0.05919941, 0.05557688, 0.0830849 , 0.05872154, 0.05208564,\n",
              "        0.08000263, 0.05932395, 0.04997555, 0.05336006, 0.04327464,\n",
              "        0.03421251, 0.05960854, 0.042576  , 0.03856047, 0.06501762,\n",
              "        0.04373233, 0.03866935, 0.06255086, 0.05381115, 0.05347133,\n",
              "        0.07622854, 0.05660335, 0.04998573, 0.07602755, 0.06263852,\n",
              "        0.05390382, 0.06259712, 0.05357138, 0.05036139, 0.08052039,\n",
              "        0.05965765, 0.04851913, 0.07737668, 0.064176  , 0.05360723,\n",
              "        0.05060625, 0.03927477, 0.03571812, 0.05921181, 0.04108206,\n",
              "        0.03372176, 0.06286216, 0.04389866, 0.03496949, 0.06105987,\n",
              "        0.0563391 , 0.05525041, 0.07646759, 0.05842702, 0.05502995,\n",
              "        0.07723395, 0.06072974, 0.05166181, 0.06239128, 0.05624406,\n",
              "        0.0492715 , 0.08306058, 0.06099637, 0.04887001, 0.07937805,\n",
              "        0.05783757, 0.04929519, 0.05144771, 0.03965569, 0.03512033,\n",
              "        0.05959169, 0.04136554, 0.03395208, 0.06332994, 0.0406061 ,\n",
              "        0.03596799, 0.07912199, 0.07364082, 0.06497566, 0.10138162,\n",
              "        0.07256651, 0.0658625 , 0.10364572, 0.07335114, 0.06467644,\n",
              "        0.08288534, 0.07235193, 0.06650321, 0.1059289 , 0.07394004,\n",
              "        0.06952969, 0.10770138, 0.07331324, 0.06122732, 0.06665564,\n",
              "        0.04889282, 0.04061842, 0.07907319, 0.04918726, 0.04366215,\n",
              "        0.07443587, 0.05182266, 0.03831251, 0.07885345, 0.07023692,\n",
              "        0.06887579, 0.10623248, 0.07094193, 0.06695016, 0.09741537,\n",
              "        0.07677205, 0.06712731, 0.07586137, 0.06928198, 0.06142227,\n",
              "        0.10380991, 0.07702414, 0.0623649 , 0.10823345, 0.0782222 ,\n",
              "        0.06782317, 0.06525405, 0.04763389, 0.03938198, 0.07902368,\n",
              "        0.0489405 , 0.03912854, 0.07660357, 0.05146464, 0.04115661,\n",
              "        0.07567286, 0.06957086, 0.06427375, 0.10782504, 0.07858046,\n",
              "        0.06536722, 0.10328682, 0.07431499, 0.0625457 , 0.0799094 ,\n",
              "        0.0708677 , 0.06402667, 0.11076633, 0.08714557, 0.08094978,\n",
              "        0.10722192, 0.09117397, 0.07054003, 0.07287415, 0.06468034,\n",
              "        0.04340219, 0.09746806, 0.05017614, 0.05012274, 0.09259597,\n",
              "        0.04822652, 0.04801401, 0.11290749, 0.10909438, 0.10573649,\n",
              "        0.16348457, 0.09333086, 0.1020635 , 0.15653284, 0.10689433,\n",
              "        0.10464629, 0.10342868, 0.11049088, 0.09883181, 0.16874035,\n",
              "        0.11659662, 0.09557501, 0.16570465, 0.12262368, 0.08596238,\n",
              "        0.10350211, 0.0706377 , 0.05522966, 0.10876226, 0.07252288,\n",
              "        0.05639132, 0.1129059 , 0.06621877, 0.0556167 , 0.11222633,\n",
              "        0.23310669, 0.08078369, 0.21532234, 0.17807929, 0.07948788,\n",
              "        0.1830372 , 0.19461393, 0.12899605, 0.10513345, 0.10113732,\n",
              "        0.08592415, 0.14786506, 0.10630465, 0.08590452, 0.14814401,\n",
              "        0.09926335, 0.08082302, 0.08726454, 0.05894796, 0.04658635,\n",
              "        0.1009086 , 0.06091913, 0.04732863, 0.1017487 , 0.06094758,\n",
              "        0.0506676 , 0.10530615, 0.09639692, 0.0888207 , 0.13619026,\n",
              "        0.09291657, 0.08579691, 0.13784893, 0.09954913, 0.08611337,\n",
              "        0.10307368, 0.09239992, 0.08645542, 0.14999628, 0.10625235,\n",
              "        0.08501887, 0.14578168, 0.09819905, 0.08159415, 0.08893077,\n",
              "        0.06777779, 0.05365499, 0.10284956, 0.06186461, 0.04830337,\n",
              "        0.10330033, 0.06171083, 0.04229021]),\n",
              " 'mean_score_time': array([0.00428653, 0.00395695, 0.00550516, 0.00396172, 0.00391769,\n",
              "        0.00374929, 0.00393716, 0.00380079, 0.00387375, 0.00383798,\n",
              "        0.00418425, 0.00384935, 0.00399629, 0.00394185, 0.00377679,\n",
              "        0.00406019, 0.0038499 , 0.00377266, 0.00392461, 0.00374166,\n",
              "        0.00359321, 0.00398954, 0.00378823, 0.00355347, 0.00417972,\n",
              "        0.00466585, 0.00370415, 0.00388304, 0.00406075, 0.00387669,\n",
              "        0.00400527, 0.00377528, 0.00367483, 0.00388026, 0.0060389 ,\n",
              "        0.00372982, 0.00385507, 0.00418639, 0.00541584, 0.00427262,\n",
              "        0.00413418, 0.0038201 , 0.00398453, 0.00649778, 0.00498533,\n",
              "        0.0039657 , 0.00466061, 0.00359122, 0.00403317, 0.00384871,\n",
              "        0.00361753, 0.00397309, 0.00392056, 0.00365949, 0.00398183,\n",
              "        0.00377703, 0.00392803, 0.00400273, 0.00399025, 0.00375978,\n",
              "        0.00401171, 0.00441432, 0.00384665, 0.00395751, 0.00381645,\n",
              "        0.00374595, 0.0041937 , 0.00579286, 0.00386016, 0.00405097,\n",
              "        0.0038747 , 0.00382288, 0.00405637, 0.00379658, 0.00361315,\n",
              "        0.00411987, 0.00377917, 0.0036664 , 0.00393836, 0.00373681,\n",
              "        0.00355792, 0.00393057, 0.00387422, 0.00378974, 0.00384974,\n",
              "        0.00372632, 0.00370677, 0.0038387 , 0.00393105, 0.0047044 ,\n",
              "        0.00392834, 0.00379499, 0.00378291, 0.00398421, 0.00388877,\n",
              "        0.0037477 , 0.00401934, 0.0045747 , 0.00412814, 0.00396029,\n",
              "        0.00376383, 0.00389202, 0.00423654, 0.00376876, 0.00368309,\n",
              "        0.00402816, 0.00391261, 0.00369255, 0.00391396, 0.00384808,\n",
              "        0.00376622, 0.00403682, 0.00366712, 0.00384545, 0.00402888,\n",
              "        0.00383576, 0.00375525, 0.00385944, 0.00371893, 0.00373014,\n",
              "        0.00393907, 0.00380866, 0.00376272, 0.00409452, 0.00414014,\n",
              "        0.00381287, 0.00423265, 0.00383234, 0.00377496, 0.00393812,\n",
              "        0.00421468, 0.0036606 , 0.0039657 , 0.00397277, 0.00368722,\n",
              "        0.00378474, 0.00371416, 0.00369151, 0.00469422, 0.00376987,\n",
              "        0.00416247, 0.00411407, 0.00379348, 0.0037547 , 0.00385992,\n",
              "        0.00394885, 0.00375319, 0.00460029, 0.00547608, 0.00462635,\n",
              "        0.00403515, 0.00483505, 0.00433302, 0.00434844, 0.0051202 ,\n",
              "        0.00371345, 0.00506918, 0.00394503, 0.00497675, 0.00507283,\n",
              "        0.00391603, 0.00441043, 0.00419879, 0.00457764, 0.0048604 ,\n",
              "        0.00514515, 0.00374246, 0.00470821, 0.00466315, 0.00421643,\n",
              "        0.00471703, 0.00386779, 0.00485547, 0.00457335, 0.00440804,\n",
              "        0.00463438, 0.00493606, 0.00445255, 0.00468588, 0.00379086,\n",
              "        0.00490721, 0.00524076, 0.00401711, 0.00444031, 0.00460482,\n",
              "        0.00454283, 0.00650827, 0.00863036, 0.00406941, 0.00426722,\n",
              "        0.00886146, 0.00362039, 0.0068961 , 0.00787346, 0.00448116,\n",
              "        0.00396434, 0.00925167, 0.00394861, 0.00392628, 0.00387851,\n",
              "        0.0037322 , 0.00395195, 0.00380794, 0.00372036, 0.00410064,\n",
              "        0.00379912, 0.0037903 , 0.00408332, 0.0038751 , 0.00361395,\n",
              "        0.00391094, 0.00417463, 0.0038441 , 0.00399661, 0.00389528,\n",
              "        0.00387422, 0.00393271, 0.00380945, 0.00370765, 0.00384061,\n",
              "        0.00386159, 0.00387947, 0.0038542 , 0.0038414 , 0.00368134,\n",
              "        0.00378092, 0.00510597, 0.0037322 , 0.0042189 , 0.00400607,\n",
              "        0.00398215, 0.00404048, 0.00373189, 0.00402904, 0.00386914,\n",
              "        0.00397261, 0.003702  , 0.00395576, 0.003757  , 0.00367332,\n",
              "        0.00395163, 0.00549014, 0.00329328]),\n",
              " 'mean_test_recall': array([0.96154971, 0.95453216, 0.94755117, 0.95804094, 0.95453216,\n",
              "        0.94755117, 0.95804094, 0.95453216, 0.94755117, 0.96856725,\n",
              "        0.95807749, 0.95807749, 0.96856725, 0.95807749, 0.95807749,\n",
              "        0.96856725, 0.95807749, 0.95807749, 0.96856725, 0.9755848 ,\n",
              "        0.97554825, 0.97207602, 0.9755848 , 0.97554825, 0.97207602,\n",
              "        0.9755848 , 0.97554825, 0.96154971, 0.95453216, 0.94755117,\n",
              "        0.95804094, 0.95453216, 0.94755117, 0.95804094, 0.95453216,\n",
              "        0.94755117, 0.96505848, 0.95807749, 0.95807749, 0.96505848,\n",
              "        0.95807749, 0.95807749, 0.96505848, 0.95807749, 0.95807749,\n",
              "        0.96856725, 0.9755848 , 0.97554825, 0.97909357, 0.9755848 ,\n",
              "        0.97554825, 0.97909357, 0.9755848 , 0.97554825, 0.96154971,\n",
              "        0.95453216, 0.94755117, 0.95804094, 0.95453216, 0.94755117,\n",
              "        0.95804094, 0.95453216, 0.94755117, 0.96505848, 0.95807749,\n",
              "        0.95807749, 0.96505848, 0.95807749, 0.95807749, 0.96505848,\n",
              "        0.95807749, 0.95807749, 0.97207602, 0.97909357, 0.97554825,\n",
              "        0.9755848 , 0.97909357, 0.97554825, 0.9755848 , 0.97909357,\n",
              "        0.97554825, 0.95804094, 0.95105994, 0.94755117, 0.95804094,\n",
              "        0.95105994, 0.94755117, 0.95804094, 0.95105994, 0.94755117,\n",
              "        0.96856725, 0.95105994, 0.94751462, 0.96856725, 0.95105994,\n",
              "        0.94751462, 0.96856725, 0.95105994, 0.94751462, 0.97207602,\n",
              "        0.97207602, 0.96505848, 0.97207602, 0.97207602, 0.96505848,\n",
              "        0.97207602, 0.97207602, 0.96505848, 0.95804094, 0.95105994,\n",
              "        0.94755117, 0.95804094, 0.95105994, 0.94755117, 0.95804094,\n",
              "        0.95105994, 0.94755117, 0.96856725, 0.94755117, 0.94751462,\n",
              "        0.96856725, 0.94755117, 0.94751462, 0.96856725, 0.94755117,\n",
              "        0.94751462, 0.97207602, 0.97207602, 0.9685307 , 0.97207602,\n",
              "        0.97207602, 0.9685307 , 0.97207602, 0.97207602, 0.9685307 ,\n",
              "        0.95804094, 0.95105994, 0.94755117, 0.95804094, 0.95105994,\n",
              "        0.94755117, 0.95804094, 0.95105994, 0.94755117, 0.96154971,\n",
              "        0.94755117, 0.94751462, 0.96505848, 0.94755117, 0.94751462,\n",
              "        0.96505848, 0.94755117, 0.94751462, 0.97207602, 0.97207602,\n",
              "        0.97203947, 0.97207602, 0.97207602, 0.97203947, 0.97207602,\n",
              "        0.97207602, 0.97203947, 0.95105994, 0.9439693 , 0.94053363,\n",
              "        0.95105994, 0.9439693 , 0.94053363, 0.95105994, 0.9439693 ,\n",
              "        0.94053363, 0.95102339, 0.9439693 , 0.94751462, 0.95453216,\n",
              "        0.9439693 , 0.94751462, 0.95453216, 0.9439693 , 0.94751462,\n",
              "        0.97554825, 0.96154971, 0.95804094, 0.97554825, 0.96154971,\n",
              "        0.95804094, 0.97554825, 0.96154971, 0.95804094, 0.95105994,\n",
              "        0.9439693 , 0.94053363, 0.95105994, 0.9439693 , 0.94053363,\n",
              "        0.95105994, 0.9439693 , 0.94053363, 0.95102339, 0.94747807,\n",
              "        0.94751462, 0.95453216, 0.94747807, 0.94751462, 0.95453216,\n",
              "        0.94747807, 0.94751462, 0.97554825, 0.96505848, 0.95804094,\n",
              "        0.97554825, 0.96505848, 0.95804094, 0.97554825, 0.96505848,\n",
              "        0.95804094, 0.95105994, 0.9439693 , 0.94053363, 0.95105994,\n",
              "        0.9439693 , 0.94053363, 0.95105994, 0.9439693 , 0.94053363,\n",
              "        0.95102339, 0.9439693 , 0.94751462, 0.94400585, 0.9439693 ,\n",
              "        0.94751462, 0.94400585, 0.9439693 , 0.94751462, 0.97203947,\n",
              "        0.96154971, 0.96154971, 0.97554825, 0.96154971, 0.96154971,\n",
              "        0.97554825, 0.96154971, 0.96154971]),\n",
              " 'param_colsample_bytree': masked_array(data=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
              "                    0.8],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0, 0, 0,\n",
              "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                    0, 0, 0, 0, 0, 0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12,\n",
              "                    12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12,\n",
              "                    12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6,\n",
              "                    12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6,\n",
              "                    6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3,\n",
              "                    3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12,\n",
              "                    3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12,\n",
              "                    12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12,\n",
              "                    12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6,\n",
              "                    12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6,\n",
              "                    6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3,\n",
              "                    3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12,\n",
              "                    3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12, 12,\n",
              "                    12, 3, 3, 3, 6, 6, 6, 12, 12, 12, 3, 3, 3, 6, 6, 6, 12,\n",
              "                    12, 12, 3, 3, 3, 6, 6, 6, 12, 12, 12],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_child_weight': masked_array(data=[1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9, 1, 5, 9,\n",
              "                    1, 5, 9, 1, 5, 9, 1, 5, 9],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.3,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 3,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 9},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 9}],\n",
              " 'rank_test_recall': array([ 84, 136, 173, 115, 136, 173, 115, 136, 173,  56,  97,  97,  56,\n",
              "         97,  97,  56,  97,  97,  56,   6,  14,  31,   6,  14,  31,   6,\n",
              "         14,  84, 136, 173, 115, 136, 173, 115, 136, 173,  70,  97,  97,\n",
              "         70,  97,  97,  70,  97,  97,  56,   6,  14,   1,   6,  14,   1,\n",
              "          6,  14,  84, 136, 173, 115, 136, 173, 115, 136, 173,  70,  97,\n",
              "         97,  70,  97,  97,  70,  97,  97,  31,   1,  14,   6,   1,  14,\n",
              "          6,   1,  14, 115, 149, 173, 115, 149, 173, 115, 149, 173,  56,\n",
              "        149, 197,  56, 149, 197,  56, 149, 197,  31,  31,  70,  31,  31,\n",
              "         70,  31,  31,  70, 115, 149, 173, 115, 149, 173, 115, 149, 173,\n",
              "         56, 173, 197,  56, 173, 197,  56, 173, 197,  31,  31,  67,  31,\n",
              "         31,  67,  31,  31,  67, 115, 149, 173, 115, 149, 173, 115, 149,\n",
              "        173,  84, 173, 197,  70, 173, 197,  70, 173, 197,  31,  31,  52,\n",
              "         31,  31,  52,  31,  31,  52, 149, 220, 235, 149, 220, 235, 149,\n",
              "        220, 235, 170, 220, 197, 136, 220, 197, 136, 220, 197,  14,  84,\n",
              "        115,  14,  84, 115,  14,  84, 115, 149, 220, 235, 149, 220, 235,\n",
              "        149, 220, 235, 170, 215, 197, 136, 215, 197, 136, 215, 197,  14,\n",
              "         70, 115,  14,  70, 115,  14,  70, 115, 149, 220, 235, 149, 220,\n",
              "        235, 149, 220, 235, 170, 220, 197, 218, 220, 197, 218, 220, 197,\n",
              "         52,  84,  84,  14,  84,  84,  14,  84,  84], dtype=int32),\n",
              " 'split0_test_recall': array([0.95833333, 0.95833333, 0.94791667, 0.95833333, 0.95833333,\n",
              "        0.94791667, 0.95833333, 0.95833333, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.94791667, 0.95833333, 0.94791667, 0.94791667,\n",
              "        0.95833333, 0.94791667, 0.94791667, 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.96875   , 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.95833333, 0.95833333, 0.94791667, 0.95833333, 0.95833333,\n",
              "        0.94791667, 0.95833333, 0.94791667, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.94791667, 0.95833333, 0.94791667, 0.94791667,\n",
              "        0.95833333, 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.94791667, 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.95833333, 0.95833333, 0.94791667, 0.95833333, 0.94791667,\n",
              "        0.94791667, 0.95833333, 0.94791667, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.94791667, 0.95833333, 0.95833333, 0.96875   ,\n",
              "        0.95833333, 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.94791667, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.94791667, 0.95833333, 0.94791667, 0.94791667,\n",
              "        0.95833333, 0.94791667, 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.95833333, 0.95833333, 0.94791667, 0.95833333, 0.95833333,\n",
              "        0.95833333, 0.95833333, 0.95833333, 0.95833333, 0.95833333,\n",
              "        0.95833333, 0.95833333, 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.94791667, 0.95833333, 0.94791667, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.94791667, 0.95833333, 0.94791667, 0.95833333,\n",
              "        0.95833333, 0.94791667, 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.95833333, 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.96875   , 0.95833333, 0.95833333, 0.96875   ,\n",
              "        0.95833333, 0.94791667, 0.94791667, 0.95833333, 0.94791667,\n",
              "        0.94791667, 0.95833333, 0.94791667, 0.94791667, 0.95833333,\n",
              "        0.94791667, 0.95833333, 0.95833333, 0.94791667, 0.95833333,\n",
              "        0.95833333, 0.94791667, 0.95833333, 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.96875   , 0.94791667, 0.96875   , 0.94791667,\n",
              "        0.94791667, 0.96875   , 0.94791667, 0.94791667, 0.96875   ,\n",
              "        0.94791667, 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.96875   , 0.95833333, 0.95833333, 0.94791667,\n",
              "        0.96875   , 0.94791667, 0.94791667, 0.96875   , 0.94791667,\n",
              "        0.94791667, 0.96875   , 0.94791667, 0.95833333, 0.96875   ,\n",
              "        0.95833333, 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.96875   , 0.95833333,\n",
              "        0.95833333, 0.94791667, 0.96875   , 0.94791667, 0.94791667,\n",
              "        0.96875   , 0.94791667, 0.94791667, 0.96875   , 0.94791667,\n",
              "        0.95833333, 0.96875   , 0.95833333, 0.95833333, 0.96875   ,\n",
              "        0.95833333, 0.95833333, 0.96875   , 0.95833333, 0.96875   ,\n",
              "        0.95833333, 0.95833333, 0.96875   , 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.95833333, 0.95833333]),\n",
              " 'split1_test_recall': array([0.95789474, 0.94736842, 0.93684211, 0.95789474, 0.94736842,\n",
              "        0.93684211, 0.95789474, 0.94736842, 0.93684211, 0.96842105,\n",
              "        0.94736842, 0.95789474, 0.96842105, 0.94736842, 0.95789474,\n",
              "        0.96842105, 0.94736842, 0.95789474, 0.96842105, 0.97894737,\n",
              "        0.97894737, 0.98947368, 0.97894737, 0.97894737, 0.98947368,\n",
              "        0.97894737, 0.97894737, 0.95789474, 0.94736842, 0.93684211,\n",
              "        0.95789474, 0.94736842, 0.93684211, 0.95789474, 0.94736842,\n",
              "        0.93684211, 0.95789474, 0.94736842, 0.95789474, 0.96842105,\n",
              "        0.94736842, 0.95789474, 0.96842105, 0.94736842, 0.95789474,\n",
              "        0.96842105, 0.97894737, 0.97894737, 0.98947368, 0.97894737,\n",
              "        0.97894737, 0.98947368, 0.97894737, 0.97894737, 0.95789474,\n",
              "        0.94736842, 0.93684211, 0.95789474, 0.94736842, 0.93684211,\n",
              "        0.95789474, 0.94736842, 0.93684211, 0.95789474, 0.94736842,\n",
              "        0.95789474, 0.96842105, 0.94736842, 0.95789474, 0.96842105,\n",
              "        0.94736842, 0.95789474, 0.97894737, 0.97894737, 0.97894737,\n",
              "        0.98947368, 0.97894737, 0.97894737, 0.98947368, 0.97894737,\n",
              "        0.97894737, 0.95789474, 0.93684211, 0.92631579, 0.95789474,\n",
              "        0.93684211, 0.92631579, 0.95789474, 0.93684211, 0.92631579,\n",
              "        0.96842105, 0.93684211, 0.93684211, 0.96842105, 0.93684211,\n",
              "        0.93684211, 0.96842105, 0.93684211, 0.93684211, 0.96842105,\n",
              "        0.96842105, 0.95789474, 0.96842105, 0.96842105, 0.95789474,\n",
              "        0.96842105, 0.96842105, 0.95789474, 0.95789474, 0.93684211,\n",
              "        0.92631579, 0.95789474, 0.93684211, 0.92631579, 0.95789474,\n",
              "        0.93684211, 0.92631579, 0.96842105, 0.93684211, 0.93684211,\n",
              "        0.96842105, 0.93684211, 0.93684211, 0.96842105, 0.93684211,\n",
              "        0.93684211, 0.96842105, 0.96842105, 0.95789474, 0.96842105,\n",
              "        0.96842105, 0.95789474, 0.96842105, 0.96842105, 0.95789474,\n",
              "        0.95789474, 0.93684211, 0.92631579, 0.95789474, 0.93684211,\n",
              "        0.92631579, 0.95789474, 0.93684211, 0.92631579, 0.94736842,\n",
              "        0.93684211, 0.93684211, 0.95789474, 0.93684211, 0.93684211,\n",
              "        0.95789474, 0.93684211, 0.93684211, 0.96842105, 0.96842105,\n",
              "        0.96842105, 0.96842105, 0.96842105, 0.96842105, 0.96842105,\n",
              "        0.96842105, 0.96842105, 0.94736842, 0.93684211, 0.92631579,\n",
              "        0.94736842, 0.93684211, 0.92631579, 0.94736842, 0.93684211,\n",
              "        0.92631579, 0.94736842, 0.92631579, 0.93684211, 0.94736842,\n",
              "        0.92631579, 0.93684211, 0.94736842, 0.92631579, 0.93684211,\n",
              "        0.96842105, 0.95789474, 0.94736842, 0.96842105, 0.95789474,\n",
              "        0.94736842, 0.96842105, 0.95789474, 0.94736842, 0.94736842,\n",
              "        0.93684211, 0.92631579, 0.94736842, 0.93684211, 0.92631579,\n",
              "        0.94736842, 0.93684211, 0.92631579, 0.94736842, 0.92631579,\n",
              "        0.93684211, 0.94736842, 0.92631579, 0.93684211, 0.94736842,\n",
              "        0.92631579, 0.93684211, 0.96842105, 0.95789474, 0.94736842,\n",
              "        0.96842105, 0.95789474, 0.94736842, 0.96842105, 0.95789474,\n",
              "        0.94736842, 0.94736842, 0.93684211, 0.92631579, 0.94736842,\n",
              "        0.93684211, 0.92631579, 0.94736842, 0.93684211, 0.92631579,\n",
              "        0.94736842, 0.92631579, 0.93684211, 0.92631579, 0.92631579,\n",
              "        0.93684211, 0.92631579, 0.92631579, 0.93684211, 0.96842105,\n",
              "        0.95789474, 0.95789474, 0.96842105, 0.95789474, 0.95789474,\n",
              "        0.96842105, 0.95789474, 0.95789474]),\n",
              " 'split2_test_recall': array([0.96842105, 0.95789474, 0.95789474, 0.95789474, 0.95789474,\n",
              "        0.95789474, 0.95789474, 0.95789474, 0.95789474, 0.97894737,\n",
              "        0.97894737, 0.96842105, 0.97894737, 0.97894737, 0.96842105,\n",
              "        0.97894737, 0.97894737, 0.96842105, 0.97894737, 0.98947368,\n",
              "        0.97894737, 0.96842105, 0.98947368, 0.97894737, 0.96842105,\n",
              "        0.98947368, 0.97894737, 0.96842105, 0.95789474, 0.95789474,\n",
              "        0.95789474, 0.95789474, 0.95789474, 0.95789474, 0.95789474,\n",
              "        0.95789474, 0.97894737, 0.97894737, 0.96842105, 0.96842105,\n",
              "        0.97894737, 0.96842105, 0.96842105, 0.97894737, 0.96842105,\n",
              "        0.97894737, 0.98947368, 0.97894737, 0.98947368, 0.98947368,\n",
              "        0.97894737, 0.98947368, 0.98947368, 0.97894737, 0.96842105,\n",
              "        0.95789474, 0.95789474, 0.95789474, 0.95789474, 0.95789474,\n",
              "        0.95789474, 0.95789474, 0.95789474, 0.97894737, 0.97894737,\n",
              "        0.96842105, 0.96842105, 0.97894737, 0.96842105, 0.96842105,\n",
              "        0.97894737, 0.96842105, 0.97894737, 1.        , 0.97894737,\n",
              "        0.97894737, 1.        , 0.97894737, 0.97894737, 1.        ,\n",
              "        0.97894737, 0.95789474, 0.96842105, 0.96842105, 0.95789474,\n",
              "        0.96842105, 0.96842105, 0.95789474, 0.96842105, 0.96842105,\n",
              "        0.97894737, 0.96842105, 0.94736842, 0.97894737, 0.96842105,\n",
              "        0.94736842, 0.97894737, 0.96842105, 0.94736842, 0.98947368,\n",
              "        0.98947368, 0.97894737, 0.98947368, 0.98947368, 0.97894737,\n",
              "        0.98947368, 0.98947368, 0.97894737, 0.95789474, 0.96842105,\n",
              "        0.96842105, 0.95789474, 0.96842105, 0.96842105, 0.95789474,\n",
              "        0.96842105, 0.96842105, 0.97894737, 0.95789474, 0.94736842,\n",
              "        0.97894737, 0.95789474, 0.94736842, 0.97894737, 0.95789474,\n",
              "        0.94736842, 0.98947368, 0.98947368, 0.97894737, 0.98947368,\n",
              "        0.98947368, 0.97894737, 0.98947368, 0.98947368, 0.97894737,\n",
              "        0.95789474, 0.96842105, 0.96842105, 0.95789474, 0.96842105,\n",
              "        0.96842105, 0.95789474, 0.96842105, 0.96842105, 0.97894737,\n",
              "        0.95789474, 0.94736842, 0.97894737, 0.95789474, 0.94736842,\n",
              "        0.97894737, 0.95789474, 0.94736842, 0.98947368, 0.98947368,\n",
              "        0.97894737, 0.98947368, 0.98947368, 0.97894737, 0.98947368,\n",
              "        0.98947368, 0.97894737, 0.95789474, 0.92631579, 0.94736842,\n",
              "        0.95789474, 0.92631579, 0.94736842, 0.95789474, 0.92631579,\n",
              "        0.94736842, 0.94736842, 0.93684211, 0.94736842, 0.95789474,\n",
              "        0.93684211, 0.94736842, 0.95789474, 0.93684211, 0.94736842,\n",
              "        0.98947368, 0.96842105, 0.96842105, 0.98947368, 0.96842105,\n",
              "        0.96842105, 0.98947368, 0.96842105, 0.96842105, 0.95789474,\n",
              "        0.92631579, 0.94736842, 0.95789474, 0.92631579, 0.94736842,\n",
              "        0.95789474, 0.92631579, 0.94736842, 0.94736842, 0.94736842,\n",
              "        0.94736842, 0.95789474, 0.94736842, 0.94736842, 0.95789474,\n",
              "        0.94736842, 0.94736842, 0.98947368, 0.97894737, 0.96842105,\n",
              "        0.98947368, 0.97894737, 0.96842105, 0.98947368, 0.97894737,\n",
              "        0.96842105, 0.95789474, 0.92631579, 0.94736842, 0.95789474,\n",
              "        0.92631579, 0.94736842, 0.95789474, 0.92631579, 0.94736842,\n",
              "        0.94736842, 0.93684211, 0.94736842, 0.94736842, 0.93684211,\n",
              "        0.94736842, 0.94736842, 0.93684211, 0.94736842, 0.97894737,\n",
              "        0.96842105, 0.96842105, 0.98947368, 0.96842105, 0.96842105,\n",
              "        0.98947368, 0.96842105, 0.96842105]),\n",
              " 'std_fit_time': array([6.47481221e-02, 1.96336325e-03, 4.94185567e-04, 2.55885177e-03,\n",
              "        4.58694234e-03, 1.62290076e-03, 1.56131254e-03, 2.01857566e-03,\n",
              "        1.85722037e-04, 9.84573809e-04, 2.18542310e-03, 5.87044761e-03,\n",
              "        5.62232306e-03, 1.75893931e-03, 3.51383245e-03, 9.47366944e-04,\n",
              "        2.06580699e-03, 8.12390713e-04, 2.50122468e-03, 3.22512506e-03,\n",
              "        1.05696872e-04, 2.61583589e-03, 3.16896213e-03, 4.81962864e-03,\n",
              "        7.36599604e-03, 2.30350608e-03, 4.66353401e-03, 3.69514195e-03,\n",
              "        1.81840090e-03, 2.84043995e-03, 1.80950425e-03, 1.91962602e-03,\n",
              "        9.10989796e-04, 2.22312570e-03, 4.50721155e-03, 5.51801113e-03,\n",
              "        4.00548446e-03, 1.74170071e-03, 2.65358084e-03, 3.06586945e-03,\n",
              "        2.10462267e-03, 7.15529257e-04, 7.06743057e-04, 1.12893795e-02,\n",
              "        1.33811694e-03, 7.94507369e-04, 5.60998810e-04, 3.65420791e-03,\n",
              "        9.10709338e-04, 9.30863329e-04, 2.87242731e-04, 3.03515010e-03,\n",
              "        1.83451774e-03, 9.97599753e-04, 4.71830413e-03, 2.56939266e-03,\n",
              "        6.97552873e-03, 2.47497269e-03, 3.19361305e-03, 4.98612985e-03,\n",
              "        1.25214020e-03, 1.14206894e-03, 2.91646957e-03, 1.55076448e-03,\n",
              "        2.67445434e-03, 1.54636632e-03, 4.55498976e-03, 6.03833261e-03,\n",
              "        3.07839925e-04, 2.04267077e-03, 4.48845812e-04, 8.72107809e-04,\n",
              "        7.65962407e-04, 3.29771825e-04, 1.18209663e-03, 8.82467872e-04,\n",
              "        1.32684789e-04, 9.37476089e-04, 6.95326824e-03, 1.16659248e-03,\n",
              "        1.46202940e-03, 1.49113969e-03, 5.06709606e-03, 3.28177207e-03,\n",
              "        3.60510310e-03, 2.19502987e-03, 3.00853823e-03, 5.48871340e-03,\n",
              "        1.01970248e-03, 2.37239219e-03, 5.17559403e-03, 2.94743555e-03,\n",
              "        3.51023066e-03, 2.02236365e-03, 2.92502011e-03, 6.38810458e-03,\n",
              "        3.69259293e-03, 2.22311006e-03, 2.14975128e-04, 2.45222244e-03,\n",
              "        2.74259226e-03, 3.26167002e-03, 6.18778682e-03, 1.98049336e-03,\n",
              "        5.67279152e-03, 1.51598715e-03, 4.40011157e-03, 1.11425955e-03,\n",
              "        1.72935588e-03, 1.77459375e-03, 1.10448916e-03, 3.39587401e-03,\n",
              "        1.72218977e-03, 5.54540962e-03, 1.87994766e-03, 5.71418296e-03,\n",
              "        5.74757929e-03, 6.10951081e-04, 1.46543774e-03, 1.06674001e-03,\n",
              "        3.42981165e-03, 4.84903723e-03, 1.16198087e-03, 3.41179143e-03,\n",
              "        3.50024572e-03, 8.28178522e-04, 1.93384483e-03, 1.61581662e-03,\n",
              "        4.97182604e-04, 5.32510184e-03, 1.61344050e-03, 1.89703697e-04,\n",
              "        3.82316921e-03, 2.54328569e-03, 2.53934005e-03, 5.14783901e-04,\n",
              "        1.75680203e-03, 3.62591315e-03, 1.06453574e-02, 8.29594918e-03,\n",
              "        3.28009745e-03, 4.62499498e-03, 2.21560129e-03, 4.42811806e-04,\n",
              "        5.52222251e-03, 3.30563443e-03, 2.52633734e-03, 5.05008131e-03,\n",
              "        1.27346971e-02, 1.44693324e-02, 3.04041440e-03, 1.43727646e-02,\n",
              "        9.07039366e-03, 1.01492558e-02, 1.56761414e-02, 4.77373756e-03,\n",
              "        1.76980577e-02, 4.02601887e-03, 8.91588971e-03, 1.23050547e-02,\n",
              "        7.58384212e-04, 6.58754247e-03, 1.51155800e-02, 1.61992718e-02,\n",
              "        1.35894009e-02, 1.51231400e-02, 7.30470431e-04, 1.39902564e-02,\n",
              "        2.09996143e-02, 1.61524194e-02, 1.69916482e-02, 6.51185705e-04,\n",
              "        1.41273268e-02, 1.21285942e-02, 2.61710217e-02, 1.18302617e-02,\n",
              "        1.92046496e-02, 2.70925331e-02, 2.20565357e-02, 9.38950273e-03,\n",
              "        1.00687737e-02, 8.61552365e-03, 7.43729455e-03, 1.53798943e-02,\n",
              "        1.09761973e-02, 6.95565212e-03, 1.66519358e-02, 1.00638728e-02,\n",
              "        9.52828166e-03, 1.18659401e-02, 1.10157792e-01, 1.73739576e-03,\n",
              "        6.11590670e-02, 1.19063245e-01, 1.11871420e-03, 6.68958748e-02,\n",
              "        6.61466220e-02, 6.44320776e-02, 3.81453159e-03, 1.27354832e-02,\n",
              "        3.66171796e-03, 2.53548903e-03, 7.32029684e-03, 4.54252886e-03,\n",
              "        6.24225848e-03, 5.79852582e-03, 7.23001667e-04, 2.15397412e-03,\n",
              "        2.28882437e-03, 1.58323499e-03, 6.82343576e-03, 3.39378449e-03,\n",
              "        9.94257547e-04, 2.65912040e-03, 3.11325254e-03, 3.69103981e-03,\n",
              "        4.55121153e-03, 4.61700812e-03, 6.41620943e-03, 4.85900820e-03,\n",
              "        8.61516319e-04, 3.16971219e-03, 5.60128332e-03, 6.15332273e-03,\n",
              "        3.86856702e-03, 1.83388432e-03, 1.99921387e-03, 3.81963252e-03,\n",
              "        7.02364842e-03, 5.93920700e-03, 4.85565812e-03, 5.33332704e-03,\n",
              "        2.55448240e-03, 1.21766202e-03, 1.54819578e-03, 2.97416289e-03,\n",
              "        3.97223007e-03, 3.38127273e-03, 8.01586192e-04, 2.96788198e-03,\n",
              "        1.20673293e-03, 4.85199764e-03, 6.68939963e-03]),\n",
              " 'std_score_time': array([3.11103694e-04, 6.12614620e-05, 2.38957707e-03, 2.45021413e-05,\n",
              "        2.99288986e-04, 9.35428306e-05, 3.09383260e-05, 9.64359846e-05,\n",
              "        1.03823984e-04, 5.34969830e-05, 3.06446502e-04, 1.73779107e-04,\n",
              "        3.82334669e-05, 8.28769715e-05, 3.32033005e-05, 1.32573355e-04,\n",
              "        1.22513490e-04, 2.04932138e-05, 3.39476579e-05, 3.16545498e-05,\n",
              "        9.27998699e-05, 4.61856987e-05, 5.97716218e-05, 5.88091644e-05,\n",
              "        2.45241373e-04, 1.14997070e-03, 6.81519507e-05, 9.46727592e-05,\n",
              "        1.09248274e-04, 2.07162835e-04, 7.72891437e-06, 7.11341142e-05,\n",
              "        4.14026904e-05, 4.25058716e-05, 3.07806874e-03, 6.35306856e-05,\n",
              "        4.35213872e-05, 5.25591257e-04, 2.12156359e-03, 2.06476577e-04,\n",
              "        3.59324141e-04, 1.02533726e-04, 3.84055421e-05, 2.20847570e-03,\n",
              "        1.70841033e-03, 1.20575127e-04, 1.24836507e-03, 6.88432242e-05,\n",
              "        5.52124216e-05, 1.74836679e-05, 1.07542902e-04, 1.32141739e-04,\n",
              "        1.32445330e-04, 5.69279799e-05, 8.40769521e-05, 7.36871567e-05,\n",
              "        3.25941035e-04, 2.28851480e-05, 1.35764722e-04, 3.31074815e-05,\n",
              "        4.14827013e-05, 5.34218774e-04, 6.44033266e-05, 1.24089484e-04,\n",
              "        5.56196474e-05, 1.35206156e-04, 2.72743931e-04, 2.69280403e-03,\n",
              "        7.85823039e-05, 1.66597559e-05, 1.14695665e-04, 1.24260740e-04,\n",
              "        2.49362761e-04, 4.67640889e-05, 9.00869648e-05, 1.43090878e-05,\n",
              "        5.64768609e-05, 7.01990567e-05, 5.51073084e-05, 2.56669040e-05,\n",
              "        1.11767890e-04, 1.39551264e-05, 2.09094166e-04, 6.75181697e-05,\n",
              "        6.71395637e-05, 2.18707808e-05, 3.71348364e-05, 6.19595817e-05,\n",
              "        3.44095475e-04, 1.25857711e-03, 3.44608103e-05, 2.27039370e-05,\n",
              "        6.93633729e-05, 8.73649307e-05, 9.62790653e-05, 5.95009219e-05,\n",
              "        6.74917851e-05, 1.19772212e-03, 6.11219631e-04, 3.90562009e-05,\n",
              "        5.22821496e-05, 2.04191869e-04, 2.86808357e-04, 7.15934467e-05,\n",
              "        7.77763650e-05, 1.16228398e-04, 1.32723911e-04, 1.49083925e-04,\n",
              "        2.96805330e-05, 1.35221103e-04, 8.68067026e-05, 4.35701210e-05,\n",
              "        4.99159156e-05, 4.25335003e-05, 2.43226632e-04, 1.04718755e-04,\n",
              "        2.58288017e-05, 5.02960869e-05, 2.80688870e-05, 6.01525030e-05,\n",
              "        3.51591740e-05, 6.25797174e-05, 3.62506022e-05, 1.33915895e-05,\n",
              "        2.05180024e-04, 1.61941431e-05, 3.60862147e-04, 5.97716218e-05,\n",
              "        2.47913010e-04, 3.32479721e-05, 5.12540331e-04, 7.90652312e-05,\n",
              "        8.07490404e-05, 3.71066484e-04, 6.45788262e-05, 2.77088026e-05,\n",
              "        1.48476062e-05, 5.13946750e-05, 1.03169573e-03, 1.43766206e-04,\n",
              "        4.32759006e-04, 6.74783081e-05, 3.67242012e-05, 3.68186703e-05,\n",
              "        8.93867964e-05, 2.00203885e-04, 2.78089152e-05, 9.40138865e-04,\n",
              "        1.50705676e-03, 5.15519571e-04, 8.13009297e-05, 7.77063791e-04,\n",
              "        8.89094902e-04, 7.03809312e-04, 8.14478354e-04, 1.58919451e-04,\n",
              "        6.62568515e-04, 3.62415132e-04, 9.16036470e-04, 8.15757057e-04,\n",
              "        2.27589319e-04, 6.66303062e-04, 6.44521962e-04, 1.13789274e-03,\n",
              "        9.58588002e-04, 1.14980448e-04, 7.59925951e-05, 7.08619307e-04,\n",
              "        5.66702802e-04, 6.51558704e-04, 7.69032160e-04, 5.37037813e-05,\n",
              "        6.62618874e-04, 6.99770376e-04, 5.59713883e-04, 5.90932300e-04,\n",
              "        1.13592929e-03, 4.87899970e-04, 4.55806733e-04, 7.06652720e-05,\n",
              "        6.14436776e-04, 1.06989416e-03, 5.12757499e-04, 5.31163955e-04,\n",
              "        5.94410782e-04, 6.37310924e-04, 2.42516044e-03, 6.84856730e-03,\n",
              "        6.22587025e-04, 7.45995009e-04, 7.32808107e-03, 6.54666334e-05,\n",
              "        4.21801512e-03, 5.96278674e-03, 1.17771097e-03, 1.61742285e-04,\n",
              "        7.33049148e-03, 1.82708225e-04, 1.25801144e-04, 1.37101717e-04,\n",
              "        5.76217146e-05, 5.01115296e-05, 5.75076068e-05, 5.68038067e-05,\n",
              "        1.85793643e-04, 4.36179317e-05, 1.75381927e-04, 1.48271737e-05,\n",
              "        2.44402212e-04, 6.57023814e-05, 6.57016123e-05, 4.41108321e-04,\n",
              "        1.57870110e-04, 9.40012429e-05, 2.21452318e-04, 2.01226442e-04,\n",
              "        1.10021499e-04, 1.48568384e-04, 2.74094969e-05, 1.88590285e-05,\n",
              "        1.37587192e-04, 1.72419698e-04, 1.12590185e-04, 1.27722207e-04,\n",
              "        9.32641013e-05, 7.01994166e-05, 1.52502544e-03, 1.46052868e-05,\n",
              "        4.65958899e-04, 1.73324167e-04, 2.47282660e-04, 2.06349134e-04,\n",
              "        3.54596821e-05, 2.62194828e-04, 5.26958399e-05, 1.95536217e-04,\n",
              "        1.45296689e-04, 7.10538923e-05, 1.11074062e-04, 1.34907561e-04,\n",
              "        1.64382920e-04, 2.52816043e-03, 5.62095789e-04]),\n",
              " 'std_test_recall': array([0.00486207, 0.00506869, 0.00859859, 0.00020676, 0.00506869,\n",
              "        0.00859859, 0.00020676, 0.00506869, 0.00859859, 0.00841628,\n",
              "        0.01475893, 0.00837188, 0.00841628, 0.01475893, 0.00837188,\n",
              "        0.00841628, 0.01475893, 0.00837188, 0.00841628, 0.01293343,\n",
              "        0.00480709, 0.01297304, 0.01293343, 0.00480709, 0.01297304,\n",
              "        0.01293343, 0.00480709, 0.00486207, 0.00506869, 0.00859859,\n",
              "        0.00020676, 0.00506869, 0.00859859, 0.00020676, 0.00506869,\n",
              "        0.00859859, 0.00982256, 0.01475893, 0.00837188, 0.0047554 ,\n",
              "        0.01475893, 0.00837188, 0.0047554 , 0.01475893, 0.00837188,\n",
              "        0.00841628, 0.01293343, 0.00480709, 0.0146797 , 0.01293343,\n",
              "        0.00480709, 0.0146797 , 0.01293343, 0.00480709, 0.00486207,\n",
              "        0.00506869, 0.00859859, 0.00020676, 0.00506869, 0.00859859,\n",
              "        0.00020676, 0.00506869, 0.00859859, 0.00982256, 0.01475893,\n",
              "        0.00837188, 0.0047554 , 0.01475893, 0.00837188, 0.0047554 ,\n",
              "        0.01475893, 0.00837188, 0.00971755, 0.01701066, 0.00480709,\n",
              "        0.01293343, 0.01701066, 0.00480709, 0.01293343, 0.01701066,\n",
              "        0.00480709, 0.00020676, 0.01308224, 0.01719134, 0.00020676,\n",
              "        0.01308224, 0.01719134, 0.00020676, 0.01308224, 0.01719134,\n",
              "        0.00841628, 0.01308224, 0.00877437, 0.00841628, 0.01308224,\n",
              "        0.00877437, 0.00841628, 0.01308224, 0.00877437, 0.01297304,\n",
              "        0.01297304, 0.00982256, 0.01297304, 0.01297304, 0.00982256,\n",
              "        0.01297304, 0.01297304, 0.00982256, 0.00020676, 0.01308224,\n",
              "        0.01719134, 0.00020676, 0.01308224, 0.01719134, 0.00020676,\n",
              "        0.01308224, 0.01719134, 0.00841628, 0.00859859, 0.00877437,\n",
              "        0.00841628, 0.00859859, 0.00877437, 0.00841628, 0.00859859,\n",
              "        0.00877437, 0.01297304, 0.01297304, 0.0085961 , 0.01297304,\n",
              "        0.01297304, 0.0085961 , 0.01297304, 0.01297304, 0.0085961 ,\n",
              "        0.00020676, 0.01308224, 0.01719134, 0.00020676, 0.01308224,\n",
              "        0.01719134, 0.00020676, 0.01308224, 0.01719134, 0.01309112,\n",
              "        0.00859859, 0.00877437, 0.00982256, 0.00859859, 0.00877437,\n",
              "        0.00982256, 0.00859859, 0.00877437, 0.01297304, 0.01297304,\n",
              "        0.00488646, 0.01297304, 0.01297304, 0.00488646, 0.01297304,\n",
              "        0.01297304, 0.00488646, 0.00483811, 0.01804186, 0.01005602,\n",
              "        0.00483811, 0.01804186, 0.01005602, 0.00483811, 0.01804186,\n",
              "        0.01005602, 0.00516891, 0.01804186, 0.00877437, 0.00506869,\n",
              "        0.01804186, 0.00877437, 0.00506869, 0.01804186, 0.00877437,\n",
              "        0.00984769, 0.00486207, 0.00859719, 0.00984769, 0.00486207,\n",
              "        0.00859719, 0.00984769, 0.00486207, 0.00859719, 0.00483811,\n",
              "        0.01804186, 0.01005602, 0.00483811, 0.01804186, 0.01005602,\n",
              "        0.00483811, 0.01804186, 0.01005602, 0.00516891, 0.01732387,\n",
              "        0.00877437, 0.00506869, 0.01732387, 0.00877437, 0.00506869,\n",
              "        0.01732387, 0.00877437, 0.00984769, 0.00982256, 0.00859719,\n",
              "        0.00984769, 0.00982256, 0.00859719, 0.00984769, 0.00982256,\n",
              "        0.00859719, 0.00483811, 0.01804186, 0.01005602, 0.00483811,\n",
              "        0.01804186, 0.01005602, 0.00483811, 0.01804186, 0.01005602,\n",
              "        0.00516891, 0.01804186, 0.00877437, 0.01328561, 0.01804186,\n",
              "        0.00877437, 0.01328561, 0.01804186, 0.00877437, 0.00488646,\n",
              "        0.00486207, 0.00486207, 0.00984769, 0.00486207, 0.00486207,\n",
              "        0.00984769, 0.00486207, 0.00486207])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wktNPjq3Tb7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9a8d36-b8b3-41a2-f4d1-12a403e5d7e5"
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_recall']\n",
        "stds = grid_result.cv_results_['std_test_recall']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.979094 using {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.965058 (0.004755) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.965058 (0.004755) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.979094 (0.014680) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.979094 (0.014680) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.965058 (0.004755) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.965058 (0.004755) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.958077 (0.014759) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.958077 (0.008372) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.972076 (0.009718) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.979094 (0.017011) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.979094 (0.017011) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.975585 (0.012933) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.979094 (0.017011) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.975548 (0.004807) with: {'colsample_bytree': 0.3, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.968567 (0.008416) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.968531 (0.008596) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.968531 (0.008596) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.968531 (0.008596) with: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.958041 (0.000207) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.951060 (0.013082) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947551 (0.017191) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.961550 (0.013091) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.947551 (0.008599) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.972039 (0.004886) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.972039 (0.004886) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.972076 (0.012973) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.972039 (0.004886) with: {'colsample_bytree': 0.5, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951023 (0.005169) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951023 (0.005169) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.947478 (0.017324) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.947478 (0.017324) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.954532 (0.005069) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.947478 (0.017324) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.965058 (0.009823) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.958041 (0.008597) with: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.951060 (0.004838) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.940534 (0.010056) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.951023 (0.005169) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.944006 (0.013286) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.944006 (0.013286) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.943969 (0.018042) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.947515 (0.008774) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 9}\n",
            "0.972039 (0.004886) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 9}\n",
            "0.975548 (0.009848) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 1}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 5}\n",
            "0.961550 (0.004862) with: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcY_7AY-WF3x"
      },
      "source": [
        "## Grid Search Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV7-obnrTb3h"
      },
      "source": [
        "xgboost_gs = XGBClassifier(colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1).fit(X_train,y_train)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOOVlxp3XeuA"
      },
      "source": [
        "## Grid Search Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NRFndxRTbzu"
      },
      "source": [
        "y_test_prob = xgboost_gs.predict_proba(X_test)[:,1]\n",
        "y_test_predict = xgboost_gs.predict(X_test)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzTob5siTbv0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "2460ab9a-9194-446b-df90-f57ad4733a28"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.989319</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998543</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999208</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.989319               1\n",
              "70     1.225780          -0.500666  ...     0.001732               0\n",
              "131    0.175418          -0.594561  ...     0.003250               0\n",
              "431   -0.547998           0.417599  ...     0.998543               1\n",
              "540   -0.428529           0.874216  ...     0.999208               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XJW7G9aYDMg"
      },
      "source": [
        "## Grid Search Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ja0z2ckTbrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3f250a2e-e3f9-49b5-a19b-d72b8afb390b"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "from sklearn import metrics\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHq5029bTbn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfffd86d-cdb7-4a37-c797-87b21363f8e1"
      },
      "source": [
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09916658096246242"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLTNbRhIYyiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a310964c-4760-4dde-c617-a60e075fea42"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        40         3\n",
            "true:yes        1        70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP6mmL7ZYycq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb9c01d-bbe7-4ee6-94af-962a831b07a3"
      },
      "source": [
        "print(classification_report(y_test, y_test_predict, digits=3))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.976     0.930     0.952        43\n",
            "           1      0.959     0.986     0.972        71\n",
            "\n",
            "    accuracy                          0.965       114\n",
            "   macro avg      0.967     0.958     0.962       114\n",
            "weighted avg      0.965     0.965     0.965       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CNoCU0VYyW7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "01ada5e7-9eff-4f59-e7b6-6ecc3cfec00d"
      },
      "source": [
        "Coeff = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(xgboost_gs.feature_importances_))], axis = 1)\n",
        "Coeff.columns=['Variable','Feature_Importance']\n",
        "CoeffSorted = Coeff.sort_values(by='Feature_Importance', ascending=False)\n",
        "CoeffSorted"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>Feature_Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>worst perimeter</td>\n",
              "      <td>0.220260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>worst concave points</td>\n",
              "      <td>0.121168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mean concavity</td>\n",
              "      <td>0.113353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>worst radius</td>\n",
              "      <td>0.075156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>worst area</td>\n",
              "      <td>0.056587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mean radius</td>\n",
              "      <td>0.050274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean concave points</td>\n",
              "      <td>0.044541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>worst compactness</td>\n",
              "      <td>0.041862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>mean perimeter</td>\n",
              "      <td>0.038211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area error</td>\n",
              "      <td>0.024386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>worst concavity</td>\n",
              "      <td>0.024315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mean texture</td>\n",
              "      <td>0.019396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>worst texture</td>\n",
              "      <td>0.019204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>concavity error</td>\n",
              "      <td>0.014941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mean area</td>\n",
              "      <td>0.013383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>worst symmetry</td>\n",
              "      <td>0.012196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>radius error</td>\n",
              "      <td>0.012054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mean fractal dimension</td>\n",
              "      <td>0.011338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>smoothness error</td>\n",
              "      <td>0.011270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mean compactness</td>\n",
              "      <td>0.010761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fractal dimension error</td>\n",
              "      <td>0.010603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>compactness error</td>\n",
              "      <td>0.007096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>mean symmetry</td>\n",
              "      <td>0.007082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>worst fractal dimension</td>\n",
              "      <td>0.007082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>worst smoothness</td>\n",
              "      <td>0.006861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>perimeter error</td>\n",
              "      <td>0.006608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>mean smoothness</td>\n",
              "      <td>0.006230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>texture error</td>\n",
              "      <td>0.005967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>symmetry error</td>\n",
              "      <td>0.004563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>concave points error</td>\n",
              "      <td>0.003252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Variable  Feature_Importance\n",
              "25          worst perimeter            0.220260\n",
              "22     worst concave points            0.121168\n",
              "8            mean concavity            0.113353\n",
              "26             worst radius            0.075156\n",
              "20               worst area            0.056587\n",
              "11              mean radius            0.050274\n",
              "7       mean concave points            0.044541\n",
              "21        worst compactness            0.041862\n",
              "10           mean perimeter            0.038211\n",
              "0                area error            0.024386\n",
              "23          worst concavity            0.024315\n",
              "14             mean texture            0.019396\n",
              "29            worst texture            0.019204\n",
              "3           concavity error            0.014941\n",
              "5                 mean area            0.013383\n",
              "28           worst symmetry            0.012196\n",
              "16             radius error            0.012054\n",
              "9    mean fractal dimension            0.011338\n",
              "17         smoothness error            0.011270\n",
              "6          mean compactness            0.010761\n",
              "4   fractal dimension error            0.010603\n",
              "1         compactness error            0.007096\n",
              "13            mean symmetry            0.007082\n",
              "24  worst fractal dimension            0.007082\n",
              "27         worst smoothness            0.006861\n",
              "15          perimeter error            0.006608\n",
              "12          mean smoothness            0.006230\n",
              "19            texture error            0.005967\n",
              "18           symmetry error            0.004563\n",
              "2      concave points error            0.003252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5JsZztaahv"
      },
      "source": [
        "## Grid Search Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wovS7efFYyOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e2c0fabc-3759-40f8-c5ff-be9ae368477c"
      },
      "source": [
        "ax = sns.barplot(x='Feature_Importance', y='Variable', data=CoeffSorted, order=CoeffSorted['Variable'])\n",
        "ax.set_xlabel('Feature Importance')\n",
        "ax.set_ylabel('Features')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Features')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1iI6ts2a4EK"
      },
      "source": [
        "## Grid Search Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49QAu6wmYyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "48c9c225-0f70-4623-f297-d24642b1e112"
      },
      "source": [
        "# Plot the predicted probability distribution\n",
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9221775f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl73esJ1Yx-a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "29f86f08-f82e-4848-d9b4-2d115810aa11"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qul0TkT6ewvK"
      },
      "source": [
        "## Random Search Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGdcYM7jdtno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112647b7-b3fd-479d-864e-d2ca2753618e"
      },
      "source": [
        "# Randome Search param_grid\n",
        "param_grid = {\n",
        "# \n",
        " \"learning_rate\": [0.0001, 0.001, 0.01, 0.1] ,\n",
        "# The maximum depth of a tree, same as GBM.\n",
        " 'max_depth':range(10,21,2),\n",
        "# This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.    \n",
        " 'min_child_weight':range(1,6,2),\n",
        "#  node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.    \n",
        " 'gamma':[i/10.0 for i in range(0,5)],\n",
        "# Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.    \n",
        " 'subsample':[i/10.0 for i in range(6,10)],\n",
        "# Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
        " 'colsample_bytree':[i/10.0 for i in range(5,10)],\n",
        "# Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.    \n",
        " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
        "# L1 regularization\n",
        " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 10, 100]\n",
        "    }\n",
        "param_grid"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
              " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              " 'learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
              " 'max_depth': range(10, 21, 2),\n",
              " 'min_child_weight': range(1, 6, 2),\n",
              " 'reg_alpha': [1e-05, 0.01, 0.1, 1, 10, 100],\n",
              " 'subsample': [0.75, 0.8, 0.85]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iREBDSpYdtkV"
      },
      "source": [
        "scoring = ['recall']"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw761X2UdthT"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bo6YuUKdtdo"
      },
      "source": [
        "random_search = RandomizedSearchCV(xgboost, param_grid, n_iter=100,scoring=scoring, refit='recall', n_jobs=-1, cv=kfold, verbose=1)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZR8beRJdtW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79efab37-330e-4196-d52d-23f3bb19c0fe"
      },
      "source": [
        "random_result = random_search.fit(X_train, y_train)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   14.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1zCQzbWdtTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934f583e-b62c-4908-a7e2-dfcb52ea1f17"
      },
      "source": [
        "random_result"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='bi...\n",
              "                   param_distributions={'colsample_bytree': [0.5, 0.6, 0.7, 0.8,\n",
              "                                                             0.9],\n",
              "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
              "                                                          0.1],\n",
              "                                        'max_depth': range(10, 21, 2),\n",
              "                                        'min_child_weight': range(1, 6, 2),\n",
              "                                        'reg_alpha': [1e-05, 0.01, 0.1, 1, 10,\n",
              "                                                      100],\n",
              "                                        'subsample': [0.75, 0.8, 0.85]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit='recall',\n",
              "                   return_train_score=False, scoring=['recall'], verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMecGsfrdtP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b656ff-b836-4342-c348-33c64cd5f7fb"
      },
      "source": [
        "random_result.cv_results_"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.13054816, 0.08090027, 0.10184669, 0.09370295, 0.118529  ,\n",
              "        0.04502575, 0.08317733, 0.09159501, 0.09219964, 0.07391588,\n",
              "        0.08812682, 0.05051184, 0.04290096, 0.04653001, 0.07488044,\n",
              "        0.04296931, 0.12569205, 0.10251085, 0.07660381, 0.04779712,\n",
              "        0.09892209, 0.0907433 , 0.05149984, 0.09112517, 0.04352427,\n",
              "        0.09157228, 0.07622186, 0.06936916, 0.10865545, 0.11654139,\n",
              "        0.04451418, 0.10036055, 0.08224106, 0.09671203, 0.13002531,\n",
              "        0.10368474, 0.10561935, 0.1091667 , 0.04420408, 0.10608872,\n",
              "        0.11293499, 0.06777827, 0.09312638, 0.08210286, 0.05260921,\n",
              "        0.04794272, 0.07414285, 0.0407021 , 0.09292539, 0.046242  ,\n",
              "        0.0846804 , 0.12381419, 0.0962708 , 0.04050748, 0.05711285,\n",
              "        0.10904026, 0.03762857, 0.0474999 , 0.06490485, 0.13911279,\n",
              "        0.08518569, 0.04507875, 0.09383988, 0.08882991, 0.03739754,\n",
              "        0.09777912, 0.08894706, 0.04267327, 0.09071263, 0.14099685,\n",
              "        0.07083162, 0.0479056 , 0.0586822 , 0.07717005, 0.07163366,\n",
              "        0.12034806, 0.08156689, 0.12479281, 0.04366493, 0.0450027 ,\n",
              "        0.07883803, 0.07869196, 0.10590013, 0.08444619, 0.08828028,\n",
              "        0.06213172, 0.07668249, 0.07932242, 0.03890991, 0.08163015,\n",
              "        0.05237563, 0.10674063, 0.12686682, 0.12969891, 0.12371731,\n",
              "        0.08783976, 0.09223954, 0.03834383, 0.10426124, 0.05315471]),\n",
              " 'mean_score_time': array([0.00387208, 0.00417662, 0.00481272, 0.00545835, 0.00388853,\n",
              "        0.00349959, 0.00364486, 0.00418266, 0.00398858, 0.00381581,\n",
              "        0.00385221, 0.00353694, 0.00367634, 0.00357485, 0.00395274,\n",
              "        0.00352812, 0.00403531, 0.0038813 , 0.00384919, 0.00456214,\n",
              "        0.00381923, 0.0038588 , 0.00352836, 0.00402641, 0.00388622,\n",
              "        0.00380135, 0.00477735, 0.00377798, 0.0038751 , 0.00394297,\n",
              "        0.00351357, 0.00386477, 0.00422859, 0.00379793, 0.00385459,\n",
              "        0.00405121, 0.00577871, 0.0040578 , 0.00350237, 0.00382193,\n",
              "        0.00405582, 0.00376821, 0.00404787, 0.00394932, 0.00385308,\n",
              "        0.00382797, 0.0039738 , 0.00365615, 0.00435384, 0.00351413,\n",
              "        0.00382781, 0.00389306, 0.00383592, 0.00366338, 0.00396919,\n",
              "        0.0039746 , 0.00361522, 0.00366847, 0.00380405, 0.00406456,\n",
              "        0.00377615, 0.00372855, 0.00382368, 0.00510955, 0.00360624,\n",
              "        0.00381438, 0.00379578, 0.00364804, 0.00374158, 0.00562946,\n",
              "        0.00391928, 0.0034798 , 0.00389806, 0.00374079, 0.00436441,\n",
              "        0.00407306, 0.00462222, 0.00394503, 0.00370034, 0.00357064,\n",
              "        0.00379682, 0.0037264 , 0.00380286, 0.00374802, 0.00380119,\n",
              "        0.00387009, 0.00389266, 0.00398548, 0.00365408, 0.00387319,\n",
              "        0.00354822, 0.00404684, 0.00434399, 0.00427842, 0.00399478,\n",
              "        0.00388281, 0.00395759, 0.00372036, 0.00397094, 0.00297038]),\n",
              " 'mean_test_recall': array([0.94762427, 0.95105994, 0.95113304, 0.9755848 , 0.9686038 ,\n",
              "        0.        , 0.96162281, 0.9755848 , 0.94053363, 0.97554825,\n",
              "        0.9686038 , 0.        , 0.        , 0.        , 0.96505848,\n",
              "        0.        , 0.9686038 , 0.95113304, 0.98603801, 0.        ,\n",
              "        0.95113304, 0.96158626, 0.        , 0.9755848 , 0.        ,\n",
              "        0.95456871, 0.9686038 , 0.97554825, 0.94762427, 0.9686038 ,\n",
              "        0.        , 0.9686038 , 0.9686038 , 0.95804094, 0.96154971,\n",
              "        0.95807749, 0.95113304, 0.9686038 , 0.        , 0.9441155 ,\n",
              "        0.96509503, 0.98252924, 0.98256579, 0.96509503, 0.        ,\n",
              "        0.        , 0.98256579, 0.        , 0.95113304, 0.        ,\n",
              "        0.96162281, 0.9686038 , 0.95807749, 0.        , 0.97207602,\n",
              "        0.96513158, 0.        , 0.        , 0.98256579, 0.97913012,\n",
              "        0.96158626, 0.        , 0.96151316, 0.96158626, 0.        ,\n",
              "        0.95113304, 0.95456871, 0.        , 0.95811404, 0.97211257,\n",
              "        0.96509503, 0.        , 0.98600146, 0.9686038 , 0.9685307 ,\n",
              "        0.97562135, 0.9686038 , 0.9686038 , 0.        , 0.        ,\n",
              "        0.97211257, 0.95456871, 0.95113304, 0.97207602, 0.94755117,\n",
              "        0.97905702, 0.95453216, 0.95453216, 0.        , 0.95456871,\n",
              "        0.        , 0.9441155 , 0.97562135, 0.96509503, 0.9686038 ,\n",
              "        0.95456871, 0.9686038 , 0.        , 0.95105994, 0.96154971]),\n",
              " 'param_colsample_bytree': masked_array(data=[0.9, 0.6, 0.7, 0.5, 0.7, 0.8, 0.6, 0.5, 0.8, 0.9, 0.5,\n",
              "                    0.9, 0.6, 0.6, 0.6, 0.7, 0.8, 0.8, 0.9, 0.9, 0.8, 0.5,\n",
              "                    0.9, 0.5, 0.6, 0.8, 0.5, 0.8, 0.8, 0.7, 0.8, 0.6, 0.5,\n",
              "                    0.8, 0.9, 0.9, 0.9, 0.7, 0.6, 0.8, 0.8, 0.8, 0.5, 0.5,\n",
              "                    0.9, 0.8, 0.8, 0.5, 0.7, 0.7, 0.6, 0.8, 0.8, 0.5, 0.6,\n",
              "                    0.8, 0.5, 0.7, 0.9, 0.9, 0.7, 0.8, 0.8, 0.8, 0.5, 0.7,\n",
              "                    0.7, 0.6, 0.7, 0.8, 0.5, 0.9, 0.8, 0.5, 0.5, 0.7, 0.9,\n",
              "                    0.8, 0.7, 0.8, 0.6, 0.6, 0.9, 0.6, 0.8, 0.9, 0.5, 0.6,\n",
              "                    0.5, 0.6, 0.9, 0.9, 0.7, 0.8, 0.7, 0.8, 0.5, 0.5, 0.9,\n",
              "                    0.5],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0.1, 0.0, 0.0, 0.0, 0.2, 0.0, 0.3, 0.4, 0.0, 0.3, 0.1,\n",
              "                    0.2, 0.1, 0.0, 0.2, 0.3, 0.4, 0.0, 0.3, 0.1, 0.3, 0.3,\n",
              "                    0.1, 0.1, 0.4, 0.1, 0.2, 0.3, 0.1, 0.1, 0.3, 0.1, 0.3,\n",
              "                    0.3, 0.1, 0.4, 0.1, 0.2, 0.2, 0.3, 0.4, 0.1, 0.2, 0.2,\n",
              "                    0.1, 0.2, 0.3, 0.1, 0.0, 0.4, 0.2, 0.2, 0.0, 0.3, 0.1,\n",
              "                    0.1, 0.2, 0.2, 0.4, 0.1, 0.3, 0.4, 0.3, 0.2, 0.4, 0.0,\n",
              "                    0.4, 0.3, 0.2, 0.4, 0.2, 0.0, 0.0, 0.2, 0.1, 0.4, 0.0,\n",
              "                    0.3, 0.1, 0.0, 0.4, 0.4, 0.3, 0.4, 0.1, 0.3, 0.0, 0.0,\n",
              "                    0.1, 0.4, 0.1, 0.4, 0.4, 0.0, 0.3, 0.2, 0.2, 0.0, 0.0,\n",
              "                    0.0],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.0001, 0.001, 0.1, 0.001, 0.001,\n",
              "                    0.0001, 0.1, 0.001, 0.01, 0.1, 0.1, 0.01, 0.01, 0.001,\n",
              "                    0.001, 0.1, 0.001, 0.0001, 0.0001, 0.0001, 0.001, 0.01,\n",
              "                    0.0001, 0.001, 0.1, 0.001, 0.01, 0.0001, 0.001, 0.01,\n",
              "                    0.01, 0.001, 0.01, 0.0001, 0.001, 0.0001, 0.0001,\n",
              "                    0.001, 0.1, 0.01, 0.01, 0.01, 0.01, 0.1, 0.001, 0.001,\n",
              "                    0.1, 0.001, 0.01, 0.01, 0.001, 0.1, 0.01, 0.01, 0.0001,\n",
              "                    0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.001, 0.001,\n",
              "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.0001, 0.01, 0.01,\n",
              "                    0.1, 0.001, 0.1, 0.0001, 0.1, 0.001, 0.0001, 0.1,\n",
              "                    0.0001, 0.1, 0.0001, 0.0001, 0.001, 0.0001, 0.1,\n",
              "                    0.0001, 0.01, 0.0001, 0.001, 0.0001, 0.001, 0.01,\n",
              "                    0.0001, 0.0001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[18, 18, 10, 16, 16, 10, 18, 18, 16, 20, 10, 16, 14, 16,\n",
              "                    16, 12, 12, 14, 10, 12, 16, 10, 16, 20, 14, 16, 16, 18,\n",
              "                    14, 10, 18, 18, 10, 20, 10, 10, 20, 10, 20, 10, 12, 16,\n",
              "                    20, 20, 12, 10, 18, 16, 20, 14, 20, 10, 14, 16, 18, 20,\n",
              "                    12, 18, 12, 18, 14, 16, 14, 14, 12, 20, 14, 10, 20, 12,\n",
              "                    10, 16, 18, 16, 10, 16, 12, 14, 16, 18, 20, 10, 20, 14,\n",
              "                    10, 18, 16, 16, 20, 10, 18, 18, 18, 16, 14, 16, 16, 14,\n",
              "                    10, 10],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_child_weight': masked_array(data=[3, 5, 3, 1, 1, 5, 3, 1, 5, 3, 1, 1, 3, 5, 5, 3, 1, 3,\n",
              "                    3, 5, 3, 1, 5, 1, 1, 5, 3, 3, 3, 1, 3, 1, 3, 5, 1, 3,\n",
              "                    3, 1, 5, 3, 1, 3, 1, 5, 1, 1, 3, 5, 3, 3, 3, 1, 3, 5,\n",
              "                    3, 3, 5, 3, 5, 1, 5, 3, 5, 5, 3, 3, 5, 1, 3, 1, 5, 5,\n",
              "                    5, 3, 5, 1, 3, 1, 5, 5, 1, 5, 3, 1, 5, 5, 5, 3, 5, 5,\n",
              "                    1, 3, 1, 1, 1, 5, 1, 5, 5, 5],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_reg_alpha': masked_array(data=[0.01, 10, 0.01, 0.01, 1e-05, 100, 0.01, 0.1, 10, 0.01,\n",
              "                    1, 100, 100, 100, 0.01, 100, 0.1, 0.1, 1, 100, 0.01,\n",
              "                    10, 100, 0.01, 100, 1e-05, 0.01, 1e-05, 0.01, 0.01,\n",
              "                    100, 0.1, 1, 0.01, 10, 10, 0.1, 1, 100, 1e-05, 1,\n",
              "                    1e-05, 1e-05, 0.1, 100, 100, 0.01, 100, 1e-05, 100,\n",
              "                    0.1, 1, 10, 100, 1e-05, 0.01, 100, 100, 1, 0.01, 0.1,\n",
              "                    100, 1, 1e-05, 100, 0.1, 0.1, 100, 1, 1e-05, 0.1, 100,\n",
              "                    0.01, 0.01, 1, 0.1, 10, 0.01, 100, 100, 10, 0.01, 0.1,\n",
              "                    10, 1, 1e-05, 1, 10, 100, 1e-05, 100, 1, 0.1, 0.01,\n",
              "                    1e-05, 1e-05, 1, 100, 0.01, 1e-05],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_subsample': masked_array(data=[0.8, 0.75, 0.85, 0.8, 0.85, 0.85, 0.75, 0.8, 0.8, 0.75,\n",
              "                    0.8, 0.75, 0.8, 0.85, 0.75, 0.8, 0.85, 0.75, 0.85,\n",
              "                    0.85, 0.75, 0.85, 0.75, 0.85, 0.75, 0.75, 0.75, 0.8,\n",
              "                    0.85, 0.75, 0.8, 0.75, 0.8, 0.85, 0.85, 0.8, 0.75,\n",
              "                    0.85, 0.8, 0.85, 0.75, 0.75, 0.75, 0.85, 0.8, 0.8, 0.8,\n",
              "                    0.75, 0.8, 0.85, 0.85, 0.8, 0.85, 0.8, 0.75, 0.8, 0.75,\n",
              "                    0.8, 0.85, 0.75, 0.85, 0.8, 0.85, 0.8, 0.8, 0.85, 0.85,\n",
              "                    0.8, 0.85, 0.85, 0.8, 0.85, 0.75, 0.75, 0.75, 0.85,\n",
              "                    0.75, 0.8, 0.85, 0.75, 0.8, 0.85, 0.75, 0.85, 0.8, 0.8,\n",
              "                    0.8, 0.75, 0.85, 0.85, 0.75, 0.85, 0.85, 0.85, 0.85,\n",
              "                    0.75, 0.8, 0.85, 0.85, 0.75],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 12,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 10,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 20,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.6,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.1,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 3,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.4,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 18,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.1,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.3,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.8,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.001,\n",
              "   'max_depth': 16,\n",
              "   'min_child_weight': 1,\n",
              "   'reg_alpha': 1,\n",
              "   'subsample': 0.8},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.01,\n",
              "   'max_depth': 14,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.9,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 0.01,\n",
              "   'subsample': 0.85},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.0001,\n",
              "   'max_depth': 10,\n",
              "   'min_child_weight': 5,\n",
              "   'reg_alpha': 1e-05,\n",
              "   'subsample': 0.75}],\n",
              " 'rank_test_recall': array([69, 67, 60, 11, 20, 75, 41, 11, 74, 14, 20, 75, 75, 75, 40, 75, 20,\n",
              "        60,  1, 75, 60, 43, 75, 11, 75, 53, 20, 14, 69, 20, 75, 20, 20, 52,\n",
              "        46, 50, 60, 20, 75, 72, 36,  6,  3, 36, 75, 75,  3, 75, 60, 75, 41,\n",
              "        20, 50, 75, 18, 35, 75, 75,  3,  7, 45, 75, 48, 43, 75, 60, 53, 75,\n",
              "        49, 16, 36, 75,  2, 20, 34,  9, 20, 20, 75, 75, 16, 53, 60, 18, 71,\n",
              "         8, 58, 58, 75, 53, 75, 72,  9, 36, 20, 53, 20, 75, 67, 46],\n",
              "       dtype=int32),\n",
              " 'split0_test_recall': array([0.92708333, 0.94791667, 0.92708333, 0.95833333, 0.94791667,\n",
              "        0.        , 0.9375    , 0.95833333, 0.94791667, 0.96875   ,\n",
              "        0.94791667, 0.        , 0.        , 0.        , 0.95833333,\n",
              "        0.        , 0.94791667, 0.92708333, 0.97916667, 0.        ,\n",
              "        0.92708333, 0.94791667, 0.        , 0.95833333, 0.        ,\n",
              "        0.94791667, 0.94791667, 0.96875   , 0.92708333, 0.94791667,\n",
              "        0.        , 0.94791667, 0.94791667, 0.95833333, 0.95833333,\n",
              "        0.94791667, 0.92708333, 0.94791667, 0.        , 0.92708333,\n",
              "        0.94791667, 0.97916667, 0.96875   , 0.94791667, 0.        ,\n",
              "        0.        , 0.96875   , 0.        , 0.92708333, 0.        ,\n",
              "        0.9375    , 0.94791667, 0.94791667, 0.        , 0.95833333,\n",
              "        0.9375    , 0.        , 0.        , 0.96875   , 0.94791667,\n",
              "        0.94791667, 0.        , 0.96875   , 0.94791667, 0.        ,\n",
              "        0.92708333, 0.94791667, 0.        , 0.9375    , 0.94791667,\n",
              "        0.94791667, 0.        , 0.98958333, 0.94791667, 0.96875   ,\n",
              "        0.94791667, 0.94791667, 0.94791667, 0.        , 0.        ,\n",
              "        0.94791667, 0.94791667, 0.92708333, 0.95833333, 0.94791667,\n",
              "        0.96875   , 0.95833333, 0.95833333, 0.        , 0.94791667,\n",
              "        0.        , 0.92708333, 0.94791667, 0.94791667, 0.94791667,\n",
              "        0.94791667, 0.94791667, 0.        , 0.94791667, 0.95833333]),\n",
              " 'split1_test_recall': array([0.97894737, 0.96842105, 0.97894737, 1.        , 1.        ,\n",
              "        0.        , 0.98947368, 1.        , 0.97894737, 0.98947368,\n",
              "        0.98947368, 0.        , 0.        , 0.        , 0.98947368,\n",
              "        0.        , 1.        , 0.97894737, 0.98947368, 0.        ,\n",
              "        0.97894737, 0.97894737, 0.        , 1.        , 0.        ,\n",
              "        0.96842105, 0.98947368, 0.97894737, 0.97894737, 0.98947368,\n",
              "        0.        , 0.98947368, 0.98947368, 0.96842105, 0.97894737,\n",
              "        0.97894737, 0.97894737, 1.        , 0.        , 0.97894737,\n",
              "        0.98947368, 0.98947368, 1.        , 0.98947368, 0.        ,\n",
              "        0.        , 0.98947368, 0.        , 0.97894737, 0.        ,\n",
              "        0.98947368, 1.        , 0.97894737, 0.        , 0.98947368,\n",
              "        0.98947368, 0.        , 0.        , 1.        , 1.        ,\n",
              "        0.98947368, 0.        , 0.97894737, 0.97894737, 0.        ,\n",
              "        0.97894737, 0.97894737, 0.        , 0.97894737, 1.        ,\n",
              "        0.98947368, 0.        , 0.98947368, 0.98947368, 0.98947368,\n",
              "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
              "        1.        , 0.97894737, 0.97894737, 1.        , 0.97894737,\n",
              "        1.        , 0.97894737, 0.96842105, 0.        , 0.97894737,\n",
              "        0.        , 0.97894737, 1.        , 1.        , 1.        ,\n",
              "        0.96842105, 0.98947368, 0.        , 0.97894737, 0.97894737]),\n",
              " 'split2_test_recall': array([0.93684211, 0.93684211, 0.94736842, 0.96842105, 0.95789474,\n",
              "        0.        , 0.95789474, 0.96842105, 0.89473684, 0.96842105,\n",
              "        0.96842105, 0.        , 0.        , 0.        , 0.94736842,\n",
              "        0.        , 0.95789474, 0.94736842, 0.98947368, 0.        ,\n",
              "        0.94736842, 0.95789474, 0.        , 0.96842105, 0.        ,\n",
              "        0.94736842, 0.96842105, 0.97894737, 0.93684211, 0.96842105,\n",
              "        0.        , 0.96842105, 0.96842105, 0.94736842, 0.94736842,\n",
              "        0.94736842, 0.94736842, 0.95789474, 0.        , 0.92631579,\n",
              "        0.95789474, 0.97894737, 0.97894737, 0.95789474, 0.        ,\n",
              "        0.        , 0.98947368, 0.        , 0.94736842, 0.        ,\n",
              "        0.95789474, 0.95789474, 0.94736842, 0.        , 0.96842105,\n",
              "        0.96842105, 0.        , 0.        , 0.97894737, 0.98947368,\n",
              "        0.94736842, 0.        , 0.93684211, 0.95789474, 0.        ,\n",
              "        0.94736842, 0.93684211, 0.        , 0.95789474, 0.96842105,\n",
              "        0.95789474, 0.        , 0.97894737, 0.96842105, 0.94736842,\n",
              "        0.97894737, 0.95789474, 0.95789474, 0.        , 0.        ,\n",
              "        0.96842105, 0.93684211, 0.94736842, 0.95789474, 0.91578947,\n",
              "        0.96842105, 0.92631579, 0.93684211, 0.        , 0.93684211,\n",
              "        0.        , 0.92631579, 0.97894737, 0.94736842, 0.95789474,\n",
              "        0.94736842, 0.96842105, 0.        , 0.92631579, 0.94736842]),\n",
              " 'std_fit_time': array([0.0204005 , 0.00701414, 0.00230874, 0.00748983, 0.00853937,\n",
              "        0.00053041, 0.00564375, 0.00494751, 0.00886608, 0.00372458,\n",
              "        0.00307053, 0.0009408 , 0.00113617, 0.00102852, 0.00315141,\n",
              "        0.00131079, 0.00514014, 0.00853371, 0.00186022, 0.00100709,\n",
              "        0.00606939, 0.00727017, 0.00315277, 0.0016132 , 0.00418959,\n",
              "        0.00503474, 0.00409545, 0.00125917, 0.00415209, 0.0016599 ,\n",
              "        0.00032374, 0.0019476 , 0.00783812, 0.00547337, 0.00327736,\n",
              "        0.00220158, 0.00584495, 0.00247852, 0.005925  , 0.00338124,\n",
              "        0.00159557, 0.00276976, 0.0014659 , 0.01680604, 0.00296661,\n",
              "        0.00137776, 0.0043222 , 0.00372908, 0.00515748, 0.0027552 ,\n",
              "        0.00199054, 0.00357956, 0.00116936, 0.00275562, 0.00047419,\n",
              "        0.00581654, 0.00042155, 0.00217048, 0.00273933, 0.00403022,\n",
              "        0.00227852, 0.00066055, 0.00472029, 0.00171746, 0.00040601,\n",
              "        0.00369624, 0.00465555, 0.00252983, 0.00202316, 0.00685215,\n",
              "        0.00514995, 0.00171151, 0.00258908, 0.00378355, 0.00338471,\n",
              "        0.00227942, 0.00407899, 0.00476795, 0.00209625, 0.00027065,\n",
              "        0.00085311, 0.00530863, 0.00154501, 0.00099541, 0.00078926,\n",
              "        0.00400235, 0.00372452, 0.00121652, 0.00073282, 0.00095493,\n",
              "        0.00297019, 0.00285806, 0.00366127, 0.00551027, 0.00607481,\n",
              "        0.00185698, 0.00217564, 0.00088179, 0.00678186, 0.01100569]),\n",
              " 'std_score_time': array([7.19169224e-05, 3.82569387e-04, 9.59191891e-04, 1.84880479e-03,\n",
              "        3.71363671e-05, 3.13060532e-05, 1.46160550e-04, 1.10973085e-04,\n",
              "        1.46208508e-04, 1.81629827e-05, 5.60972566e-05, 5.86881106e-05,\n",
              "        9.74087660e-05, 9.93460972e-05, 2.33645909e-04, 1.18708034e-04,\n",
              "        3.19513059e-04, 5.05208663e-05, 1.59461734e-04, 1.23034292e-03,\n",
              "        3.25002217e-05, 1.11780096e-04, 2.53068341e-05, 1.00615465e-04,\n",
              "        2.69999611e-05, 4.25201338e-05, 1.09805431e-03, 3.50450982e-05,\n",
              "        1.09049217e-04, 1.26882297e-04, 3.09540412e-05, 1.30819183e-05,\n",
              "        5.13653928e-04, 4.74887412e-05, 2.59823993e-05, 3.37517577e-04,\n",
              "        2.72528034e-03, 4.06817385e-04, 5.41929154e-05, 1.51670366e-05,\n",
              "        1.94840095e-04, 3.54295677e-05, 1.64117555e-04, 1.34890331e-04,\n",
              "        2.33029576e-04, 3.69978436e-04, 1.29049193e-04, 1.50691230e-04,\n",
              "        4.96729926e-04, 7.56417986e-05, 5.01408878e-05, 3.27622948e-05,\n",
              "        5.41271439e-05, 1.05913382e-04, 2.18745376e-04, 1.41625497e-04,\n",
              "        6.83338131e-05, 3.59700519e-05, 1.03673495e-04, 1.24191290e-04,\n",
              "        3.61015033e-05, 1.62733134e-04, 1.08411060e-04, 1.60518610e-03,\n",
              "        6.72887838e-05, 2.75235522e-05, 1.02442951e-05, 1.45613192e-04,\n",
              "        2.49572619e-05, 2.18528302e-03, 2.43101879e-04, 7.95156840e-05,\n",
              "        1.59824683e-04, 1.74105429e-05, 7.78423634e-04, 1.09266888e-04,\n",
              "        1.25982102e-03, 9.47937666e-05, 1.83633320e-04, 1.96067775e-05,\n",
              "        7.83395224e-05, 5.80888437e-05, 6.39768861e-05, 5.52474149e-05,\n",
              "        7.28092850e-05, 2.92626365e-05, 1.36349304e-04, 4.21465488e-05,\n",
              "        4.67496353e-05, 1.28940496e-04, 8.82757109e-06, 1.83926641e-04,\n",
              "        5.26870465e-04, 3.39311941e-04, 1.43284783e-04, 1.21781001e-04,\n",
              "        5.07274709e-05, 1.30038242e-04, 2.04281952e-04, 5.84284908e-04]),\n",
              " 'std_test_recall': array([0.02250423, 0.01308224, 0.02134008, 0.01774856, 0.02257109,\n",
              "        0.        , 0.0213813 , 0.01774856, 0.03477293, 0.00984769,\n",
              "        0.01696607, 0.        , 0.        , 0.        , 0.01783506,\n",
              "        0.        , 0.02257109, 0.02134008, 0.00485877, 0.        ,\n",
              "        0.02134008, 0.01293436, 0.        , 0.01774856, 0.        ,\n",
              "        0.00979764, 0.01696607, 0.00480709, 0.02250423, 0.01696607,\n",
              "        0.        , 0.01696607, 0.01696607, 0.00859719, 0.01309112,\n",
              "        0.01475893, 0.02134008, 0.02257109, 0.        , 0.02463185,\n",
              "        0.01771308, 0.00491128, 0.0130118 , 0.01771308, 0.        ,\n",
              "        0.        , 0.00976924, 0.        , 0.02134008, 0.        ,\n",
              "        0.0213813 , 0.02257109, 0.01475893, 0.        , 0.01297304,\n",
              "        0.02134528, 0.        , 0.        , 0.0130118 , 0.02248571,\n",
              "        0.01972066, 0.        , 0.01793492, 0.01293436, 0.        ,\n",
              "        0.02134008, 0.01782135, 0.        , 0.01692153, 0.02142256,\n",
              "        0.01771308, 0.        , 0.0049882 , 0.01696607, 0.0171901 ,\n",
              "        0.0213926 , 0.02257109, 0.02257109, 0.        , 0.        ,\n",
              "        0.02142256, 0.01782135, 0.02134008, 0.01974605, 0.0257854 ,\n",
              "        0.01480953, 0.02165421, 0.01316926, 0.        , 0.01782135,\n",
              "        0.        , 0.02463185, 0.0213926 , 0.02468256, 0.02257109,\n",
              "        0.00979764, 0.01696607, 0.        , 0.0216014 , 0.01309112])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNlLccHJdtL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5acb31-0a15-422a-dd8a-96b257e28d9d"
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "means = random_result.cv_results_['mean_test_recall']\n",
        "stds = random_result.cv_results_['std_test_recall']\n",
        "params = random_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.982529 using {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
            "0.954678 (0.027220) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 3, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
            "0.958151 (0.022384) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.001, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "0.968567 (0.008416) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
            "0.951170 (0.024397) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.9}\n",
            "0.954642 (0.021298) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 14, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
            "0.944189 (0.029764) with: {'subsample': 0.85, 'reg_alpha': 10, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
            "0.944225 (0.038293) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.944225 (0.038293) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 5, 'max_depth': 16, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.951206 (0.032078) with: {'subsample': 0.75, 'reg_alpha': 1e-05, 'min_child_weight': 5, 'max_depth': 14, 'learning_rate': 0.0001, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
            "0.958114 (0.016922) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.9}\n",
            "0.933699 (0.027118) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.0001, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "0.937208 (0.030492) with: {'subsample': 0.8, 'reg_alpha': 1e-05, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "0.965058 (0.009823) with: {'subsample': 0.75, 'reg_alpha': 10, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.5}\n",
            "0.958151 (0.030729) with: {'subsample': 0.8, 'reg_alpha': 10, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
            "0.000000 (0.000000) with: {'subsample': 0.8, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.0001, 'gamma': 0.0, 'colsample_bytree': 0.9}\n",
            "0.951206 (0.032078) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 3, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.6}\n",
            "0.000000 (0.000000) with: {'subsample': 0.8, 'reg_alpha': 100, 'min_child_weight': 5, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "0.972039 (0.004886) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
            "0.982529 (0.004911) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
            "0.958151 (0.022384) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.001, 'gamma': 0.3, 'colsample_bytree': 0.9}\n",
            "0.965095 (0.012885) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "0.940680 (0.024346) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.001, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "0.944225 (0.035281) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.944189 (0.027169) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
            "0.975548 (0.009848) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
            "0.958151 (0.022384) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "0.940680 (0.024346) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
            "0.000000 (0.000000) with: {'subsample': 0.75, 'reg_alpha': 100, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.5}\n",
            "0.944225 (0.035281) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.6}\n",
            "0.954678 (0.027220) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
            "0.944225 (0.038293) with: {'subsample': 0.85, 'reg_alpha': 1e-05, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.958151 (0.022384) with: {'subsample': 0.8, 'reg_alpha': 1e-05, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.0001, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "0.951170 (0.025867) with: {'subsample': 0.75, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.9}\n",
            "0.947697 (0.030542) with: {'subsample': 0.85, 'reg_alpha': 10, 'min_child_weight': 3, 'max_depth': 20, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.947697 (0.030542) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.6}\n",
            "0.937208 (0.030492) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.0001, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.951170 (0.025867) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.968567 (0.008416) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
            "0.000000 (0.000000) with: {'subsample': 0.85, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.5}\n",
            "0.000000 (0.000000) with: {'subsample': 0.8, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "0.961623 (0.017590) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
            "0.958151 (0.022384) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.001, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
            "0.954678 (0.027220) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
            "0.940716 (0.034256) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.3, 'colsample_bytree': 0.7}\n",
            "0.975585 (0.017749) with: {'subsample': 0.75, 'reg_alpha': 10, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.7}\n",
            "0.947661 (0.022334) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "0.000000 (0.000000) with: {'subsample': 0.85, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.0001, 'gamma': 0.1, 'colsample_bytree': 0.7}\n",
            "0.982529 (0.004911) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
            "0.940716 (0.032027) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 16, 'learning_rate': 0.0001, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.944225 (0.038293) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.001, 'gamma': 0.1, 'colsample_bytree': 0.7}\n",
            "0.975548 (0.004807) with: {'subsample': 0.75, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.6}\n",
            "0.947734 (0.036950) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.6}\n",
            "0.961586 (0.012934) with: {'subsample': 0.8, 'reg_alpha': 10, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.0, 'colsample_bytree': 0.5}\n",
            "0.000000 (0.000000) with: {'subsample': 0.75, 'reg_alpha': 100, 'min_child_weight': 3, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.5}\n",
            "0.982529 (0.004911) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.9}\n",
            "0.933699 (0.027118) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.000000 (0.000000) with: {'subsample': 0.75, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.8}\n",
            "0.944225 (0.035281) with: {'subsample': 0.85, 'reg_alpha': 1e-05, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "0.958151 (0.022384) with: {'subsample': 0.85, 'reg_alpha': 1e-05, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.7}\n",
            "0.968567 (0.008416) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "0.944225 (0.035281) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "0.944189 (0.029764) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 18, 'learning_rate': 0.0001, 'gamma': 0.1, 'colsample_bytree': 0.5}\n",
            "0.944115 (0.012787) with: {'subsample': 0.75, 'reg_alpha': 1e-05, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.0, 'colsample_bytree': 0.7}\n",
            "0.979020 (0.000103) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
            "0.000000 (0.000000) with: {'subsample': 0.75, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.944189 (0.027169) with: {'subsample': 0.85, 'reg_alpha': 10, 'min_child_weight': 3, 'max_depth': 16, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.961586 (0.012934) with: {'subsample': 0.75, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.9}\n",
            "0.944189 (0.027169) with: {'subsample': 0.85, 'reg_alpha': 10, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.947734 (0.036950) with: {'subsample': 0.75, 'reg_alpha': 1e-05, 'min_child_weight': 3, 'max_depth': 18, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.6}\n",
            "0.940716 (0.032027) with: {'subsample': 0.75, 'reg_alpha': 1, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.0001, 'gamma': 0.2, 'colsample_bytree': 0.9}\n",
            "0.947697 (0.030542) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 3, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.965058 (0.009823) with: {'subsample': 0.75, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.0001, 'gamma': 0.0, 'colsample_bytree': 0.5}\n",
            "0.961659 (0.029887) with: {'subsample': 0.75, 'reg_alpha': 10, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.001, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
            "0.951170 (0.025867) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 3, 'max_depth': 20, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
            "0.937171 (0.022283) with: {'subsample': 0.8, 'reg_alpha': 10, 'min_child_weight': 3, 'max_depth': 18, 'learning_rate': 0.0001, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
            "0.982529 (0.004911) with: {'subsample': 0.75, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.9}\n",
            "0.961623 (0.017590) with: {'subsample': 0.85, 'reg_alpha': 1e-05, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
            "0.947697 (0.030542) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 16, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.7}\n",
            "0.000000 (0.000000) with: {'subsample': 0.85, 'reg_alpha': 100, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.965095 (0.012885) with: {'subsample': 0.8, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
            "0.982529 (0.004911) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 20, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.8}\n",
            "0.982529 (0.004911) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.8}\n",
            "0.937135 (0.016833) with: {'subsample': 0.85, 'reg_alpha': 10, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
            "0.958151 (0.022384) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 18, 'learning_rate': 0.001, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
            "0.954642 (0.021298) with: {'subsample': 0.8, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.001, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
            "0.000000 (0.000000) with: {'subsample': 0.75, 'reg_alpha': 100, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.001, 'gamma': 0.0, 'colsample_bytree': 0.6}\n",
            "0.982529 (0.004911) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
            "0.979057 (0.014810) with: {'subsample': 0.75, 'reg_alpha': 10, 'min_child_weight': 5, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
            "0.961623 (0.017590) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "0.972039 (0.004886) with: {'subsample': 0.85, 'reg_alpha': 0.01, 'min_child_weight': 5, 'max_depth': 16, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "0.954642 (0.021298) with: {'subsample': 0.75, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 20, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.6}\n",
            "0.965095 (0.012885) with: {'subsample': 0.8, 'reg_alpha': 1e-05, 'min_child_weight': 1, 'max_depth': 20, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.7}\n",
            "0.979020 (0.000103) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
            "0.947697 (0.030542) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 14, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.7}\n",
            "0.982529 (0.004911) with: {'subsample': 0.8, 'reg_alpha': 1e-05, 'min_child_weight': 3, 'max_depth': 20, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
            "0.972039 (0.004886) with: {'subsample': 0.75, 'reg_alpha': 10, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "0.968567 (0.008416) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
            "0.979020 (0.000103) with: {'subsample': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 3, 'max_depth': 16, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
            "0.951170 (0.024397) with: {'subsample': 0.85, 'reg_alpha': 1, 'min_child_weight': 1, 'max_depth': 14, 'learning_rate': 0.0001, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
            "0.940716 (0.032027) with: {'subsample': 0.85, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 14, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nd2B8VNh0OI"
      },
      "source": [
        "## Random Search Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCjxhBDBdtIn"
      },
      "source": [
        "xgboost_rs = XGBClassifier(seed=0, subsample=0.85, reg_alpha=10.1, min_child_weight=1, max_depth=18, learning_rate=0.1, gamma=0.0, colsample_bytree=0.5).fit(X_train,y_train)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f2IHtLWim4Y"
      },
      "source": [
        "## Random Search Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe9cXn5bdtEr"
      },
      "source": [
        "y_test_prob = xgboost_rs.predict_proba(X_test)[:,1]\n",
        "y_test_predict = xgboost_rs.predict(X_test)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbDW6vIxdtA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "65ded6d3-a753-4e7f-fb99-03750d0a8af5"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.957385</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058338</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.059088</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.963692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.966031</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.957385               1\n",
              "70     1.225780          -0.500666  ...     0.058338               0\n",
              "131    0.175418          -0.594561  ...     0.059088               0\n",
              "431   -0.547998           0.417599  ...     0.963692               1\n",
              "540   -0.428529           0.874216  ...     0.966031               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4doPgkijJ_0"
      },
      "source": [
        "## Random Search Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG9Z9UMuds9l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "49a7fcd4-e49e-40fd-dbbd-8ff968693ba9"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "from sklearn import metrics\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABDo4jZkds6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887fb189-df2d-4f36-8b13-729b001baf07"
      },
      "source": [
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14446483523045717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2LGF5Cds2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b53b678-e8ee-4966-aeda-df366b28f0cf"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        40         3\n",
            "true:yes        2        69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Aw-nUgdszm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cfd00b-1a77-491c-fe05-aa3741ffdcb7"
      },
      "source": [
        "print(classification_report(y_test, y_test_predict, digits=4))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9524    0.9302    0.9412        43\n",
            "           1     0.9583    0.9718    0.9650        71\n",
            "\n",
            "    accuracy                         0.9561       114\n",
            "   macro avg     0.9554    0.9510    0.9531       114\n",
            "weighted avg     0.9561    0.9561    0.9560       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv4IRopolh3r"
      },
      "source": [
        "## Random Search Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R73Fh7WPdswZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "09e2862f-ed3b-443c-b370-8bbf44578ceb"
      },
      "source": [
        "Coeff = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(xgboost_rs.feature_importances_))], axis = 1)\n",
        "Coeff.columns=['Variable','Feature_Importance']\n",
        "CoeffSorted = Coeff.sort_values(by='Feature_Importance', ascending=False)\n",
        "CoeffSorted"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>Feature_Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean concave points</td>\n",
              "      <td>0.298057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>worst perimeter</td>\n",
              "      <td>0.216578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>worst concave points</td>\n",
              "      <td>0.089430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>worst area</td>\n",
              "      <td>0.084101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>worst compactness</td>\n",
              "      <td>0.052967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mean concavity</td>\n",
              "      <td>0.045955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mean area</td>\n",
              "      <td>0.034902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>worst radius</td>\n",
              "      <td>0.026963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>worst texture</td>\n",
              "      <td>0.021188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area error</td>\n",
              "      <td>0.017616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mean texture</td>\n",
              "      <td>0.012453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>worst concavity</td>\n",
              "      <td>0.012316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>perimeter error</td>\n",
              "      <td>0.010691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>concavity error</td>\n",
              "      <td>0.010188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>mean perimeter</td>\n",
              "      <td>0.009936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mean fractal dimension</td>\n",
              "      <td>0.009588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>compactness error</td>\n",
              "      <td>0.008655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>worst symmetry</td>\n",
              "      <td>0.005520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>radius error</td>\n",
              "      <td>0.005509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>texture error</td>\n",
              "      <td>0.005131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fractal dimension error</td>\n",
              "      <td>0.005088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>worst smoothness</td>\n",
              "      <td>0.004399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>mean smoothness</td>\n",
              "      <td>0.004281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>symmetry error</td>\n",
              "      <td>0.004138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>smoothness error</td>\n",
              "      <td>0.002482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mean compactness</td>\n",
              "      <td>0.001275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>worst fractal dimension</td>\n",
              "      <td>0.000380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mean radius</td>\n",
              "      <td>0.000215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>mean symmetry</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>concave points error</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Variable  Feature_Importance\n",
              "7       mean concave points            0.298057\n",
              "25          worst perimeter            0.216578\n",
              "22     worst concave points            0.089430\n",
              "20               worst area            0.084101\n",
              "21        worst compactness            0.052967\n",
              "8            mean concavity            0.045955\n",
              "5                 mean area            0.034902\n",
              "26             worst radius            0.026963\n",
              "29            worst texture            0.021188\n",
              "0                area error            0.017616\n",
              "14             mean texture            0.012453\n",
              "23          worst concavity            0.012316\n",
              "15          perimeter error            0.010691\n",
              "3           concavity error            0.010188\n",
              "10           mean perimeter            0.009936\n",
              "9    mean fractal dimension            0.009588\n",
              "1         compactness error            0.008655\n",
              "28           worst symmetry            0.005520\n",
              "16             radius error            0.005509\n",
              "19            texture error            0.005131\n",
              "4   fractal dimension error            0.005088\n",
              "27         worst smoothness            0.004399\n",
              "12          mean smoothness            0.004281\n",
              "18           symmetry error            0.004138\n",
              "17         smoothness error            0.002482\n",
              "6          mean compactness            0.001275\n",
              "24  worst fractal dimension            0.000380\n",
              "11              mean radius            0.000215\n",
              "13            mean symmetry            0.000000\n",
              "2      concave points error            0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Xt-gdNdsr-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "6e32e623-96e6-4686-cda6-f9bc14e8ba50"
      },
      "source": [
        "ax = sns.barplot(x='Feature_Importance', y='Variable', data=CoeffSorted, order=CoeffSorted['Variable'])\n",
        "ax.set_xlabel('Feature Importance')\n",
        "ax.set_ylabel('Features')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Features')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwifHLlXmPl7"
      },
      "source": [
        "## Random Search Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVwIWpVdsot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "68f57dde-4ae0-4f57-a941-2f835239f977"
      },
      "source": [
        "# Plot the predicted probability distribution\n",
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92213ec410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK2KEwSfdslG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "3bd6adcd-d268-4e00-e888-e3eb665a27a3"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUcQPy_in8fY"
      },
      "source": [
        "## Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYCKpmz-dsgp"
      },
      "source": [
        "N_FOLDS = 3\n",
        "MAX_EVALS = 100"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcETVkW4Yx2u"
      },
      "source": [
        "# Learning rate\n",
        "learning_rate=[0.0001, 0.001, 0.01, 0.1] \n",
        "n_estimators=[100,300,500,1000]\n",
        "# The maximum depth of a tree, same as GBM.\n",
        "max_depth=range(10,21,2)\n",
        "# This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.    \n",
        "min_child_weight=range(1,6,2)\n",
        "#  node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.    \n",
        "gamma=[i/10.0 for i in range(0,5)]\n",
        "# Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.    \n",
        "subsample=[i/10.0 for i in range(6,10)]\n",
        "# Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
        "colsample_bytree=[i/10.0 for i in range(5,10)]\n",
        "# L1 regularization\n",
        "reg_alpha=[1e-5, 1e-2, 0.1, 1, 10, 100]\n",
        "    \n",
        "param = dict(learning_rate=learning_rate, n_estimators=n_estimators,max_depth=max_depth,min_child_weight=min_child_weight,gamma=gamma,subsample=subsample,colsample_bytree=colsample_bytree,reg_alpha=reg_alpha)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqH7kog5oYES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457b5a2a-e2b4-4947-f37d-a2fce493fa23"
      },
      "source": [
        "param"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
              " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              " 'learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
              " 'max_depth': range(10, 21, 2),\n",
              " 'min_child_weight': range(1, 6, 2),\n",
              " 'n_estimators': [100, 300, 500, 1000],\n",
              " 'reg_alpha': [1e-05, 0.01, 0.1, 1, 10, 100],\n",
              " 'subsample': [0.6, 0.7, 0.8, 0.9]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTzVg0qvoYN9"
      },
      "source": [
        "# Space\n",
        "space = {\n",
        "    'learning_rate': hp.choice('learning_rate', learning_rate),\n",
        "    'n_estimators': hp.choice('n_estimators', n_estimators),\n",
        "    'max_depth' : hp.choice('max_depth', max_depth),\n",
        "    'min_child_weight' : hp.choice('min_child_weight', min_child_weight),\n",
        "    'gamma' : hp.choice('gamma', gamma),\n",
        "    'subsample' : hp.choice('subsample', subsample),    \n",
        "    'colsample_bytree' : hp.choice('colsample_bytree', colsample_bytree),     \n",
        "    'reg_alpha' : hp.choice('reg_alpha', reg_alpha) \n",
        "}"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKAJqE8HoYR5"
      },
      "source": [
        "# Objective function\n",
        "def objective(params, n_folds = N_FOLDS):\n",
        "\n",
        "    # Perform n_fold cross validation with hyperparameters\n",
        "    # Use early stopping and evaluate based on ROC AUC\n",
        "    \n",
        "    xgboost = XGBClassifier(seed=0, **params)\n",
        "    scores = cross_val_score(xgboost, X_train, y_train, cv=n_folds, scoring='recall', n_jobs=-1)\n",
        "\n",
        "    # Extract the best score\n",
        "    best_score = max(scores)\n",
        "\n",
        "    # Loss must be minimized\n",
        "    loss = 1 - best_score\n",
        "\n",
        "    # Dictionary with information for evaluation\n",
        "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlnEjUnKoYVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b820f1-5e78-4c7a-b9d2-80e711cd89f0"
      },
      "source": [
        "# Algorithm\n",
        "tpe_algorithm = tpe.suggest\n",
        "\n",
        "# Trials object to track progress\n",
        "bayes_trials = Trials()\n",
        "\n",
        "# Optimize\n",
        "best = fmin(fn = objective, space = space, algo = tpe_algorithm, max_evals = MAX_EVALS, trials = bayes_trials)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:02<00:00,  1.59it/s, best loss: 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed3dBSaloYZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67e4335-3808-4d1d-f455-adf4a95b5f95"
      },
      "source": [
        "# Best parameters:\n",
        "best"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0,\n",
              " 'gamma': 4,\n",
              " 'learning_rate': 2,\n",
              " 'max_depth': 1,\n",
              " 'min_child_weight': 1,\n",
              " 'n_estimators': 3,\n",
              " 'reg_alpha': 1,\n",
              " 'subsample': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2TgDM4HoYdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cab7557-7ba9-44e9-b608-fd8f1b63191a"
      },
      "source": [
        "{'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        " 'learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
        " 'max_depth': range(10, 21, 2),\n",
        " 'min_child_weight': range(1, 6, 2),\n",
        " 'n_estimators': [100, 300, 500, 1000],\n",
        " 'reg_alpha': [1e-05, 0.01, 0.1, 1, 10, 100],\n",
        " 'subsample': [0.6, 0.7, 0.8, 0.9]}"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
              " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              " 'learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
              " 'max_depth': range(10, 21, 2),\n",
              " 'min_child_weight': range(1, 6, 2),\n",
              " 'n_estimators': [100, 300, 500, 1000],\n",
              " 'reg_alpha': [1e-05, 0.01, 0.1, 1, 10, 100],\n",
              " 'subsample': [0.6, 0.7, 0.8, 0.9]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HI7rvfZqtcQ"
      },
      "source": [
        "## Bayesian Optimization Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXfr7cGmoYgP"
      },
      "source": [
        "xgboost_bo = XGBClassifier(seed=0, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=3, subsample=0.8, reg_alpha=1, n_estimators=300).fit(X_train,y_train)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_yMKt_BoYj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c443b2-4af7-45c3-cb0c-8aa9d7a4c677"
      },
      "source": [
        "xgboost_bo.get_params()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_score': 0.5,\n",
              " 'booster': 'gbtree',\n",
              " 'colsample_bylevel': 1,\n",
              " 'colsample_bynode': 1,\n",
              " 'colsample_bytree': 0.6,\n",
              " 'gamma': 0.1,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_delta_step': 0,\n",
              " 'max_depth': 20,\n",
              " 'min_child_weight': 3,\n",
              " 'missing': None,\n",
              " 'n_estimators': 300,\n",
              " 'n_jobs': 1,\n",
              " 'nthread': None,\n",
              " 'objective': 'binary:logistic',\n",
              " 'random_state': 0,\n",
              " 'reg_alpha': 1,\n",
              " 'reg_lambda': 1,\n",
              " 'scale_pos_weight': 1,\n",
              " 'seed': 0,\n",
              " 'silent': None,\n",
              " 'subsample': 0.8,\n",
              " 'verbosity': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOkjiSD4tyBh"
      },
      "source": [
        "## Bayesian Optimization Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G6NDG5EoYoU"
      },
      "source": [
        "y_test_prob = xgboost_bo.predict_proba(X_test)[:,1]\n",
        "y_test_predict = xgboost_bo.predict(X_test)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTPQFjS2oYsZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "5e4d5b9b-da08-4d7c-e25d-c7d4cf240ae7"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.968536</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001544</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.997588</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.968536               1\n",
              "70     1.225780          -0.500666  ...     0.001373               0\n",
              "131    0.175418          -0.594561  ...     0.001544               0\n",
              "431   -0.547998           0.417599  ...     0.997588               1\n",
              "540   -0.428529           0.874216  ...     0.999184               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRgGotqVvA3C"
      },
      "source": [
        "## Bayesian Optimization Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP6sF1WyuGrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bfb25f1f-2031-4367-afef-4550de8304c2"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "from sklearn import metrics\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1TtMsnhuGms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387df20f-2c6b-4ee8-bc82-8622ab53fb9e"
      },
      "source": [
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07979581305111774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtxdInAbuGjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7265a14-db4e-497b-c771-1d43e24d0861"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        41         2\n",
            "true:yes        1        70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gokp5jgduGfv"
      },
      "source": [
        "print(classification_report(y_test, y_test_predict, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-TLMPdyx9bS"
      },
      "source": [
        "## Bayesian Optimization Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdMrPymMuGcv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "60362895-8867-4335-a9ce-cdaa28f2c2b9"
      },
      "source": [
        "Coeff = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(xgboost_bo.feature_importances_))], axis = 1)\n",
        "Coeff.columns=['Variable','Feature_Importance']\n",
        "CoeffSorted = Coeff.sort_values(by='Feature_Importance', ascending=False)\n",
        "CoeffSorted"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>Feature_Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean concave points</td>\n",
              "      <td>0.307822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>worst concave points</td>\n",
              "      <td>0.157712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>worst perimeter</td>\n",
              "      <td>0.156790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>worst area</td>\n",
              "      <td>0.081283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mean radius</td>\n",
              "      <td>0.039454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mean area</td>\n",
              "      <td>0.036256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mean concavity</td>\n",
              "      <td>0.028429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>worst radius</td>\n",
              "      <td>0.025818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>concavity error</td>\n",
              "      <td>0.022213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>worst texture</td>\n",
              "      <td>0.020510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mean texture</td>\n",
              "      <td>0.015349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>worst concavity</td>\n",
              "      <td>0.013543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>worst symmetry</td>\n",
              "      <td>0.013360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area error</td>\n",
              "      <td>0.010282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>mean perimeter</td>\n",
              "      <td>0.009117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>worst smoothness</td>\n",
              "      <td>0.007270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>texture error</td>\n",
              "      <td>0.005552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>mean smoothness</td>\n",
              "      <td>0.005415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>symmetry error</td>\n",
              "      <td>0.005194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fractal dimension error</td>\n",
              "      <td>0.005029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mean fractal dimension</td>\n",
              "      <td>0.004656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mean compactness</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>compactness error</td>\n",
              "      <td>0.004396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>perimeter error</td>\n",
              "      <td>0.004110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>radius error</td>\n",
              "      <td>0.004056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>worst fractal dimension</td>\n",
              "      <td>0.003728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>smoothness error</td>\n",
              "      <td>0.003652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>concave points error</td>\n",
              "      <td>0.002850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>mean symmetry</td>\n",
              "      <td>0.001553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>worst compactness</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Variable  Feature_Importance\n",
              "7       mean concave points            0.307822\n",
              "22     worst concave points            0.157712\n",
              "25          worst perimeter            0.156790\n",
              "20               worst area            0.081283\n",
              "11              mean radius            0.039454\n",
              "5                 mean area            0.036256\n",
              "8            mean concavity            0.028429\n",
              "26             worst radius            0.025818\n",
              "3           concavity error            0.022213\n",
              "29            worst texture            0.020510\n",
              "14             mean texture            0.015349\n",
              "23          worst concavity            0.013543\n",
              "28           worst symmetry            0.013360\n",
              "0                area error            0.010282\n",
              "10           mean perimeter            0.009117\n",
              "27         worst smoothness            0.007270\n",
              "19            texture error            0.005552\n",
              "12          mean smoothness            0.005415\n",
              "18           symmetry error            0.005194\n",
              "4   fractal dimension error            0.005029\n",
              "9    mean fractal dimension            0.004656\n",
              "6          mean compactness            0.004600\n",
              "1         compactness error            0.004396\n",
              "15          perimeter error            0.004110\n",
              "16             radius error            0.004056\n",
              "24  worst fractal dimension            0.003728\n",
              "17         smoothness error            0.003652\n",
              "2      concave points error            0.002850\n",
              "13            mean symmetry            0.001553\n",
              "21        worst compactness            0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwN4IVYuGZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fe132d63-4583-4e95-af5b-48f146913454"
      },
      "source": [
        "ax = sns.barplot(x='Feature_Importance', y='Variable', data=CoeffSorted, order=CoeffSorted['Variable'])\n",
        "ax.set_xlabel('Feature Importance')\n",
        "ax.set_ylabel('Features')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Features')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBa2BEn4yNyY"
      },
      "source": [
        "## Bayesian Optimization Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJNWcILuGU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d4f7f155-33e8-4e0c-f080-3ca5b41b39e5"
      },
      "source": [
        "# Plot the predicted probability distribution\n",
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9223eb3d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fy5zFLfuGRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "d7fa881a-7a74-463e-c8d8-14f45dc958e1"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dz7QJ1Cypqz"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCO9LpahuGMW"
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "modelname = 'xgboost_bo_model.pkl'\n",
        "pickle.dump(xgboost_bo, open(modelname, 'wb'))"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6IOA2wduGIW"
      },
      "source": [
        "# load the model from disk\n",
        "loaded_phase1_model = pickle.load(open(modelname, 'rb'))"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WLS5CndznRK"
      },
      "source": [
        "# Neutal Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh45Vj3gg1Tu"
      },
      "source": [
        "## Grid Search Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gotb22XuGEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37988508-d232-4c5b-b14b-74406f00e830"
      },
      "source": [
        "layers = [(30), (30, 15)]# Need to use tuple instead of list because of a bug related to nested list with Keras. https://datascience.stackexchange.com/questions/66341/cannot-clone-object-keras-wrappers-scikit-learn-kerasregressor-object-at-0x7fdc\n",
        "activations = ['tanh', 'relu']\n",
        "batch_size = [32, 256]\n",
        "epochs=[10, 50]\n",
        "param_grid = dict(layers=layers, activation=activations, batch_size = batch_size, epochs=epochs)\n",
        "param_grid"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['tanh', 'relu'],\n",
              " 'batch_size': [32, 256],\n",
              " 'epochs': [10, 50],\n",
              " 'layers': [30, (30, 15)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNkWyPW2uGAT"
      },
      "source": [
        "scoring = ['recall']"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHd951QFhgjp"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmWoo8Fbhgfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baf4ba1-8ac7-4a3d-f4cd-97771d4e530c"
      },
      "source": [
        "l = enumerate(layers)\n",
        "print(list(l))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 30), (1, (30, 15))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDxHaXehhgco"
      },
      "source": [
        "def create_model(layers, activation='relu', batch_size=32, epochs=50):\n",
        "    model = Sequential()\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i==0:\n",
        "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "        else:\n",
        "            model.add(Dense(nodes))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "            \n",
        "    model.add(Dense(units = 1, activation = 'sigmoid')) # Note: no activation beyond this point\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX8vsoBuLdJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544596c8-eb10-46a2-d59f-a0f7b4384f46"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "# Change function to estimator\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, scoring=scoring, refit='recall', n_jobs=-1, cv=kfold, verbose=1)\n",
        "\n",
        "grid_result = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   26.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsmwDwhnhgOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197725c9-13e9-4468-cdd1-8732d434565c"
      },
      "source": [
        "grid_result"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f922076c890>,\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'activation': ['tanh', 'relu'],\n",
              "                         'batch_size': [32, 256], 'epochs': [10, 50],\n",
              "                         'layers': [30, (30, 15)]},\n",
              "             pre_dispatch='2*n_jobs', refit='recall', return_train_score=False,\n",
              "             scoring=['recall'], verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTtOILzihgJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c19152-9537-4e99-9121-740d759fe22b"
      },
      "source": [
        "grid_result.cv_results_"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.04909539, 1.43604414, 0.0059216 , 1.89263916, 0.00589101,\n",
              "        1.00672523, 0.01386491, 1.21884608, 0.0064172 , 1.10774636,\n",
              "        0.00787306, 1.81028763, 0.00653243, 0.99039753, 0.00573874,\n",
              "        1.15260474]),\n",
              " 'mean_score_time': array([0.        , 0.22735866, 0.        , 0.17750112, 0.        ,\n",
              "        0.18391267, 0.        , 0.17998719, 0.        , 0.16996574,\n",
              "        0.        , 0.16804838, 0.        , 0.16822958, 0.        ,\n",
              "        0.14686418]),\n",
              " 'mean_test_recall': array([       nan, 0.97916667,        nan, 0.98260234,        nan,\n",
              "        0.90932018,        nan, 0.98611111,        nan, 0.97916667,\n",
              "               nan, 0.98256579,        nan, 0.8433114 ,        nan,\n",
              "        0.97913012]),\n",
              " 'param_activation': masked_array(data=['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_batch_size': masked_array(data=[32, 32, 32, 32, 256, 256, 256, 256, 32, 32, 32, 32,\n",
              "                    256, 256, 256, 256],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_epochs': masked_array(data=[10, 10, 50, 50, 10, 10, 50, 50, 10, 10, 50, 50, 10, 10,\n",
              "                    50, 50],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_layers': masked_array(data=[30, (30, 15), 30, (30, 15), 30, (30, 15), 30, (30, 15),\n",
              "                    30, (30, 15), 30, (30, 15), 30, (30, 15), 30, (30, 15)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'tanh',\n",
              "   'batch_size': 32,\n",
              "   'epochs': 10,\n",
              "   'layers': 30},\n",
              "  {'activation': 'tanh', 'batch_size': 32, 'epochs': 10, 'layers': (30, 15)},\n",
              "  {'activation': 'tanh', 'batch_size': 32, 'epochs': 50, 'layers': 30},\n",
              "  {'activation': 'tanh', 'batch_size': 32, 'epochs': 50, 'layers': (30, 15)},\n",
              "  {'activation': 'tanh', 'batch_size': 256, 'epochs': 10, 'layers': 30},\n",
              "  {'activation': 'tanh', 'batch_size': 256, 'epochs': 10, 'layers': (30, 15)},\n",
              "  {'activation': 'tanh', 'batch_size': 256, 'epochs': 50, 'layers': 30},\n",
              "  {'activation': 'tanh', 'batch_size': 256, 'epochs': 50, 'layers': (30, 15)},\n",
              "  {'activation': 'relu', 'batch_size': 32, 'epochs': 10, 'layers': 30},\n",
              "  {'activation': 'relu', 'batch_size': 32, 'epochs': 10, 'layers': (30, 15)},\n",
              "  {'activation': 'relu', 'batch_size': 32, 'epochs': 50, 'layers': 30},\n",
              "  {'activation': 'relu', 'batch_size': 32, 'epochs': 50, 'layers': (30, 15)},\n",
              "  {'activation': 'relu', 'batch_size': 256, 'epochs': 10, 'layers': 30},\n",
              "  {'activation': 'relu', 'batch_size': 256, 'epochs': 10, 'layers': (30, 15)},\n",
              "  {'activation': 'relu', 'batch_size': 256, 'epochs': 50, 'layers': 30},\n",
              "  {'activation': 'relu', 'batch_size': 256, 'epochs': 50, 'layers': (30, 15)}],\n",
              " 'rank_test_recall': array([ 9,  4, 10,  2, 11,  7, 12,  1, 13,  4, 14,  3, 15,  8, 16,  6],\n",
              "       dtype=int32),\n",
              " 'split0_test_recall': array([       nan, 0.9375    ,        nan, 0.95833333,        nan,\n",
              "        0.84375   ,        nan, 0.95833333,        nan, 0.9375    ,\n",
              "               nan, 0.96875   ,        nan, 0.65625   ,        nan,\n",
              "        0.94791667]),\n",
              " 'split1_test_recall': array([       nan, 1.        ,        nan, 1.        ,        nan,\n",
              "        0.93684211,        nan, 1.        ,        nan, 1.        ,\n",
              "               nan, 1.        ,        nan, 0.90526316,        nan,\n",
              "        0.98947368]),\n",
              " 'split2_test_recall': array([       nan, 1.        ,        nan, 0.98947368,        nan,\n",
              "        0.94736842,        nan, 1.        ,        nan, 1.        ,\n",
              "               nan, 0.97894737,        nan, 0.96842105,        nan,\n",
              "        1.        ]),\n",
              " 'std_fit_time': array([3.02117389e-02, 2.37543634e-01, 3.36315978e-04, 7.65808441e-02,\n",
              "        1.06425762e-04, 6.18135822e-02, 1.17804414e-02, 7.79473222e-02,\n",
              "        1.74711353e-04, 1.29796054e-02, 1.65716580e-03, 3.66631685e-02,\n",
              "        1.53129282e-03, 6.36843087e-02, 3.10104830e-04, 1.93145688e-01]),\n",
              " 'std_score_time': array([0.        , 0.00309957, 0.        , 0.00708629, 0.        ,\n",
              "        0.0272111 , 0.        , 0.02216976, 0.        , 0.00606299,\n",
              "        0.        , 0.00308714, 0.        , 0.00913166, 0.        ,\n",
              "        0.03173711]),\n",
              " 'std_test_recall': array([       nan, 0.02946278,        nan, 0.01769066,        nan,\n",
              "        0.04656384,        nan, 0.01964186,        nan, 0.02946278,\n",
              "               nan, 0.0130118 ,        nan, 0.13476203,        nan,\n",
              "        0.02248571])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEG6h35LhgFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bc31dc-0214-488f-97b7-5930b20b85f5"
      },
      "source": [
        "grid_result.best_score_"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9861111111111112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA7dablMMtMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbc3ff6-8a6d-4674-a531-17adb2c38c07"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh', 'batch_size': 256, 'epochs': 50, 'layers': (30, 15)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j-nGgjTM7gz"
      },
      "source": [
        "## Grid Search Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzOGMka8MtIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e0bd36-5233-4f4c-ab81-efe967c21e7e"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "start = time.time()\n",
        "nn = Sequential()\n",
        "nn.add(Dense(30,input_dim=30,activation='tanh'))\n",
        "nn.add(Dropout(0.3))\n",
        "nn.add(Dense(15,activation='tanh'))\n",
        "nn.add(Dropout(0.3))\n",
        "nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "nn.compile(loss='binary_crossentropy',optimizer='adam')   \n",
        "nn.fit(X_train,y_train, epochs=50,batch_size=256)\n",
        "end = time.time()\n",
        "fit_time = (end - start)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9592\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8602\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8082\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7231\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6665\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6082\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5822\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5077\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4912\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4471\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4123\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3975\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3518\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3529\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3302\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2850\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2836\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2847\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2585\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2545\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2504\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2377\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2353\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2070\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2104\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1957\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1866\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1865\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1937\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1844\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1776\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1819\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1578\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1721\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1609\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1542\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1418\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1388\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1361\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1426\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1301\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1353\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1414\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1376\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1305\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1160\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1360\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1398\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1103\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzLdNnilMtDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c775c01-60c2-4448-e7fc-19e6c151d60c"
      },
      "source": [
        "fit_time"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3136725425720215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YydibsV2SQ-t"
      },
      "source": [
        "## Grid Search Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnHM3PAMMs-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9302781b-0e89-4d7b-99c6-9c67a85b7866"
      },
      "source": [
        "start_time = time.time()\n",
        "y_test_predict = nn.predict_classes(X_test)\n",
        "end_time = time.time()\n",
        "predict_time = end_time - start_time\n",
        "predict_time"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08545541763305664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJHXDRMMs6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987a49be-d220-4bab-acc3-099215fae96d"
      },
      "source": [
        "y_test_prob = nn.predict_proba(X_test)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k914Y02ESmNF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "4f79b59e-c958-44d8-a4df-513cf136960e"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927778</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015543</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035639</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983302</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986347</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.927778               1\n",
              "70     1.225780          -0.500666  ...     0.015543               0\n",
              "131    0.175418          -0.594561  ...     0.035639               0\n",
              "431   -0.547998           0.417599  ...     0.983302               1\n",
              "540   -0.428529           0.874216  ...     0.986347               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLChrkKbSmIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e607d4e3-01c5-4494-9f72-e76ad30e8c43"
      },
      "source": [
        "testPred['y_test_prob'].describe()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    114.000000\n",
              "mean       0.618005\n",
              "std        0.439925\n",
              "min        0.008975\n",
              "25%        0.033756\n",
              "50%        0.953299\n",
              "75%        0.980918\n",
              "max        0.991232\n",
              "Name: y_test_prob, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ya_sdrJTTYh"
      },
      "source": [
        "## Grid Search Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmzh5trSSmC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "caeaaddc-f6c9-405c-ba58-7db63940205d"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import metrics\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh5x-NQMSl92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee79ea9-abb1-466b-dfe2-1d9bb23c4432"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08413433676520199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCXRTz8nTkoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e70701d-f96c-4c6f-8fe9-1792ed74487a"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        41         2\n",
            "true:yes        2        69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieDl27rDTkba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd0dc96-202c-4384-ae88-9e49be7353de"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_test_predict))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        43\n",
            "           1       0.97      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s8maPDtTusO"
      },
      "source": [
        "## Grid Search Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSTnhjLpSl6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "7511a002-34a4-4e23-b637-9617303489a3"
      },
      "source": [
        "# Plot the predicted probability distribution\n",
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f921957ab90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YniDpijBT9wD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "79e1bccd-f1ae-4740-ce8e-4476c6e6b179"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.kdeplot(testPred[testPred['y_test']==1]['y_test_prob'],label='traffic_keyword=1');\n",
        "sns.kdeplot(testPred[testPred['y_test']==0]['y_test_prob'],label='traffic_keyword=0');\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJP94Y0zT9id",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "20c0c098-c580-4263-8168-02a01470b3fb"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='traffic_keyword=1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='traffic_keyword=0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu3iXnyp95OJ"
      },
      "source": [
        "## Random Search Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAN3Vbcn9-9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc9a717-9536-47b1-a4ef-b5f70d7b9ee1"
      },
      "source": [
        "layers = [(30), (30, 15), (30, 15, 7), (30, 15, 7, 3)]# Need to use tuple instead of list because of a bug related to nested list with Keras. https://datascience.stackexchange.com/questions/66341/cannot-clone-object-keras-wrappers-scikit-learn-kerasregressor-object-at-0x7fdc\n",
        "activations = ['tanh', 'relu']\n",
        "kernel_initializer = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "optimizer = ['Adam', 'Adamax', 'Nadam']\n",
        "# Glorot normal initializer, also called Xavier normal initializer.\n",
        "# It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
        "batch_size = [16, 32, 64, 128, 256, 512, 1024]\n",
        "epochs=[50, 100, 150]\n",
        "dropout=[0.0, 0.1, 0.2, 0.3, 0.4]\n",
        "param_grid = dict(layers=layers, activation=activations, kernel_initializer=kernel_initializer, optimizer=optimizer, batch_size = batch_size, epochs=epochs, dropout=dropout)\n",
        "param_grid"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['tanh', 'relu'],\n",
              " 'batch_size': [16, 32, 64, 128, 256, 512, 1024],\n",
              " 'dropout': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              " 'epochs': [50, 100, 150],\n",
              " 'kernel_initializer': ['uniform',\n",
              "  'lecun_uniform',\n",
              "  'normal',\n",
              "  'zero',\n",
              "  'glorot_normal',\n",
              "  'glorot_uniform',\n",
              "  'he_normal',\n",
              "  'he_uniform'],\n",
              " 'layers': [30, (30, 15), (30, 15, 7), (30, 15, 7, 3)],\n",
              " 'optimizer': ['Adam', 'Adamax', 'Nadam']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wpQKaRI-wv2"
      },
      "source": [
        "scoring = ['recall']"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfyLvbxz-wrh"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWz8v-pP-wnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a585d2e-e6e7-4e36-d11d-d4f8d250bb13"
      },
      "source": [
        "l = enumerate(layers)\n",
        "print(list(l))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 30), (1, (30, 15)), (2, (30, 15, 7)), (3, (30, 15, 7, 3))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1GSCeyQ-wjk"
      },
      "source": [
        "def create_model(layers, activation='relu', batch_size=32, epochs=50, dropout=0.2, kernel_initializer='normal', optimizer = 'adam'):\n",
        "    # Add seed later\n",
        "    model = Sequential()\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i==0:\n",
        "            model.add(Dense(nodes,kernel_initializer=kernel_initializer, input_dim=X_train.shape[1]))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(dropout))\n",
        "        else:\n",
        "            model.add(Dense(nodes,kernel_initializer=kernel_initializer))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(dropout))\n",
        "            \n",
        "    model.add(Dense(units = 1, activation = 'sigmoid')) # Note: no activation beyond this point\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTqxMzNr-wfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abafc75b-ebf0-4867-9127-1eb3b0b14dae"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "# Change function to estimator\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_grid, scoring=scoring, refit='recall', n_jobs=-1, cv=kfold, verbose=1)\n",
        "\n",
        "random_result = random_search.fit(X_train, y_train)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   36.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-68C25v-wbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12976d44-cba5-41f0-90d9-fd7f12131ad7"
      },
      "source": [
        "random_result"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f921cf3cc50>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'activation': ['tanh', 'relu'],\n",
              "                                        'batch_size': [16, 32, 64, 128, 256,\n",
              "                                                       512, 1024],\n",
              "                                        'dropout': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              "                                        'epochs': [50, 100, 150],\n",
              "                                        'kernel_initializer': ['uniform',\n",
              "                                                               'lecun_uniform',\n",
              "                                                               'normal', 'zero',\n",
              "                                                               'glorot_normal',\n",
              "                                                               'glorot_uniform',\n",
              "                                                               'he_normal',\n",
              "                                                               'he_uniform'],\n",
              "                                        'layers': [30, (30, 15), (30, 15, 7),\n",
              "                                                   (30, 15, 7, 3)],\n",
              "                                        'optimizer': ['Adam', 'Adamax',\n",
              "                                                      'Nadam']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit='recall',\n",
              "                   return_train_score=False, scoring=['recall'], verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_0Xckr-wXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39e4c8a-79cc-494b-a8be-11bb1db7c4b4"
      },
      "source": [
        "random_result.cv_results_"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([3.61083706, 5.20785586, 1.76873716, 1.0496757 , 1.99223693,\n",
              "        1.32899682, 1.36487595, 1.98250159, 1.99438286, 1.78326845]),\n",
              " 'mean_score_time': array([0.27605136, 0.20018045, 0.29711771, 0.15666858, 0.18097933,\n",
              "        0.20042157, 0.17378775, 0.18498858, 0.1874365 , 0.15121428]),\n",
              " 'mean_test_recall': array([1.        , 1.        , 0.95102339, 0.96856725, 0.98947368,\n",
              "        0.97902047, 0.9755117 , 0.98249269, 0.97898392, 0.97902047]),\n",
              " 'param_activation': masked_array(data=['tanh', 'relu', 'tanh', 'relu', 'relu', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_batch_size': masked_array(data=[32, 16, 1024, 1024, 64, 1024, 64, 128, 128, 128],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_dropout': masked_array(data=[0.4, 0.2, 0.4, 0.3, 0.0, 0.2, 0.4, 0.1, 0.3, 0.4],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_epochs': masked_array(data=[100, 100, 50, 50, 100, 50, 50, 150, 100, 150],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_kernel_initializer': masked_array(data=['zero', 'zero', 'glorot_normal', 'glorot_uniform',\n",
              "                    'glorot_uniform', 'uniform', 'uniform',\n",
              "                    'glorot_normal', 'glorot_uniform', 'he_uniform'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_layers': masked_array(data=[(30, 15, 7), (30, 15, 7, 3), (30, 15), (30, 15),\n",
              "                    (30, 15, 7), (30, 15, 7, 3), (30, 15), (30, 15, 7),\n",
              "                    (30, 15, 7, 3), (30, 15)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_optimizer': masked_array(data=['Nadam', 'Nadam', 'Nadam', 'Adamax', 'Adamax', 'Adam',\n",
              "                    'Adamax', 'Adamax', 'Adamax', 'Adamax'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'tanh',\n",
              "   'batch_size': 32,\n",
              "   'dropout': 0.4,\n",
              "   'epochs': 100,\n",
              "   'kernel_initializer': 'zero',\n",
              "   'layers': (30, 15, 7),\n",
              "   'optimizer': 'Nadam'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 16,\n",
              "   'dropout': 0.2,\n",
              "   'epochs': 100,\n",
              "   'kernel_initializer': 'zero',\n",
              "   'layers': (30, 15, 7, 3),\n",
              "   'optimizer': 'Nadam'},\n",
              "  {'activation': 'tanh',\n",
              "   'batch_size': 1024,\n",
              "   'dropout': 0.4,\n",
              "   'epochs': 50,\n",
              "   'kernel_initializer': 'glorot_normal',\n",
              "   'layers': (30, 15),\n",
              "   'optimizer': 'Nadam'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 1024,\n",
              "   'dropout': 0.3,\n",
              "   'epochs': 50,\n",
              "   'kernel_initializer': 'glorot_uniform',\n",
              "   'layers': (30, 15),\n",
              "   'optimizer': 'Adamax'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 64,\n",
              "   'dropout': 0.0,\n",
              "   'epochs': 100,\n",
              "   'kernel_initializer': 'glorot_uniform',\n",
              "   'layers': (30, 15, 7),\n",
              "   'optimizer': 'Adamax'},\n",
              "  {'activation': 'tanh',\n",
              "   'batch_size': 1024,\n",
              "   'dropout': 0.2,\n",
              "   'epochs': 50,\n",
              "   'kernel_initializer': 'uniform',\n",
              "   'layers': (30, 15, 7, 3),\n",
              "   'optimizer': 'Adam'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 64,\n",
              "   'dropout': 0.4,\n",
              "   'epochs': 50,\n",
              "   'kernel_initializer': 'uniform',\n",
              "   'layers': (30, 15),\n",
              "   'optimizer': 'Adamax'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 128,\n",
              "   'dropout': 0.1,\n",
              "   'epochs': 150,\n",
              "   'kernel_initializer': 'glorot_normal',\n",
              "   'layers': (30, 15, 7),\n",
              "   'optimizer': 'Adamax'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 128,\n",
              "   'dropout': 0.3,\n",
              "   'epochs': 100,\n",
              "   'kernel_initializer': 'glorot_uniform',\n",
              "   'layers': (30, 15, 7, 3),\n",
              "   'optimizer': 'Adamax'},\n",
              "  {'activation': 'relu',\n",
              "   'batch_size': 128,\n",
              "   'dropout': 0.4,\n",
              "   'epochs': 150,\n",
              "   'kernel_initializer': 'he_uniform',\n",
              "   'layers': (30, 15),\n",
              "   'optimizer': 'Adamax'}],\n",
              " 'rank_test_recall': array([ 1,  1, 10,  9,  3,  5,  8,  4,  7,  5], dtype=int32),\n",
              " 'split0_test_recall': array([1.        , 1.        , 0.95833333, 0.95833333, 1.        ,\n",
              "        0.97916667, 0.97916667, 0.98958333, 0.98958333, 0.97916667]),\n",
              " 'split1_test_recall': array([1.        , 1.        , 0.91578947, 0.94736842, 0.97894737,\n",
              "        0.96842105, 0.96842105, 0.97894737, 0.97894737, 0.96842105]),\n",
              " 'split2_test_recall': array([1.        , 1.        , 0.97894737, 1.        , 0.98947368,\n",
              "        0.98947368, 0.97894737, 0.97894737, 0.96842105, 0.98947368]),\n",
              " 'std_fit_time': array([0.16148355, 0.24180401, 0.21072978, 0.01510427, 0.16692799,\n",
              "        0.01582979, 0.02532414, 0.0191525 , 0.18807204, 0.19888543]),\n",
              " 'std_score_time': array([0.06609464, 0.00915183, 0.17134437, 0.00776564, 0.00222876,\n",
              "        0.01642825, 0.00782559, 0.01190627, 0.01144236, 0.03709505]),\n",
              " 'std_test_recall': array([0.        , 0.        , 0.0262971 , 0.02267261, 0.0085947 ,\n",
              "        0.00859532, 0.00501464, 0.00501384, 0.0086395 , 0.00859532])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNqFvI5c-wTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c69f3fc-36f1-43a5-c368-2f249a92b042"
      },
      "source": [
        "random_result.best_score_"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7C6_hxd-wO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d96951f-328b-4bbf-d095-10342a3ec5b9"
      },
      "source": [
        "random_result.best_params_"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh',\n",
              " 'batch_size': 32,\n",
              " 'dropout': 0.4,\n",
              " 'epochs': 100,\n",
              " 'kernel_initializer': 'zero',\n",
              " 'layers': (30, 15, 7),\n",
              " 'optimizer': 'Nadam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA8vhA3zDrOJ"
      },
      "source": [
        "## Random Search Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOtgFbf0-wK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaedf88-1268-486e-9ffc-2ad62b7395f6"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "start = time.time()\n",
        "nn = Sequential()\n",
        "nn.add(Dense(30,input_dim=30,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(15,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(7,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(1,kernel_initializer= 'zero', activation='sigmoid'))\n",
        "\n",
        "nn.compile(loss='binary_crossentropy',optimizer='Nadam')   \n",
        "nn.fit(X_train,y_train, epochs=100,batch_size=32)\n",
        "end = time.time()\n",
        "fit_time = (end - start)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.6900\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.6689\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6277\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5738\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5326\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4863\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.4441\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.4116\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3770\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3553\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3302\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3164\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2872\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2652\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2493\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2355\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2416\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2341\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2136\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2050\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2248\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2001\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1757\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1730\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1817\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1704\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1554\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1527\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1653\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1338\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1499\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1714\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1296\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1422\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1405\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1446\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1088\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1246\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1026\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1318\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1144\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0952\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0976\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1147\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1185\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1006\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0852\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0941\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0888\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1245\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1076\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1293\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1132\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0917\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0780\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1043\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1033\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0945\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0844\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0967\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0788\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1051\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0822\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0868\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0781\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0826\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0943\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1076\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0883\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0884\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1258\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0557\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0837\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0770\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0887\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0798\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0718\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0840\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0776\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0798\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0940\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0806\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0573\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1061\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0803\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0561\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0937\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0841\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0547\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0752\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0783\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0503\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0792\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0759\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1034\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGMNJQgL-wHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cdaa8f-3455-40b2-fcca-7f0bfba0eb58"
      },
      "source": [
        "fit_time"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.253416299819946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDKcK-KKGFAc"
      },
      "source": [
        "## Random Search Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7nCyCeVGO62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1413221-4d4d-47f7-9c3a-8013422af38e"
      },
      "source": [
        "start_time = time.time()\n",
        "y_test_predict = nn.predict_classes(X_test)\n",
        "end_time = time.time()\n",
        "predict_time = end_time - start_time"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPmOKmn0GQWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b6dfbe-c8df-48c2-fa95-a2ce775d692a"
      },
      "source": [
        "predict_time"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14543366432189941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9hOVFeGQSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf6a780-68c8-4e9c-80d8-fe2d52adc42e"
      },
      "source": [
        "y_test_prob = nn.predict_proba(X_test)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWTUU5X_GQO3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "1de38cf6-f8cb-433e-c05c-1d1e29690ed5"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986192</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.018186</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.018187</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.986192               1\n",
              "70     1.225780          -0.500666  ...     0.018186               0\n",
              "131    0.175418          -0.594561  ...     0.018187               0\n",
              "431   -0.547998           0.417599  ...     0.986240               1\n",
              "540   -0.428529           0.874216  ...     0.986240               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXfE3_RILLM"
      },
      "source": [
        "## Random Search Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH9Yg_sGGQKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "524a7edc-e057-4fd0-e9a7-63bec9414d31"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wemC92p4GQGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f0d7f8-3984-45ba-e450-229aa91a3b5e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05733532113791035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TojQJdNGQCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7680ee8a-abac-46ec-e622-2528088ba756"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        42         1\n",
            "true:yes        0        71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW-G40JZGP-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a6cf19-7b56-471b-89d8-146df81c6709"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_test_predict))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.99      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.99       114\n",
            "   macro avg       0.99      0.99      0.99       114\n",
            "weighted avg       0.99      0.99      0.99       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8LwQy0IycL"
      },
      "source": [
        "## Random Search Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKpiNmx3GP6v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "39e3a227-d2c8-4ec2-ff86-e0e8803980ac"
      },
      "source": [
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f922164b310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcaUy6Z9GPzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "7294f34d-6686-406f-a4e2-c01681994b89"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6tHO3SwVbHs"
      },
      "source": [
        "## Bayesian Optimization Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL0IOMT0GPu9"
      },
      "source": [
        "N_FOLDS = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "MAX_EVALS = 2"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA7sw9afGPq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb341bc-f0ba-458e-9e6e-bc1f9a2004b9"
      },
      "source": [
        "layers = [(30), (30, 15), (30, 15, 7), (30, 15, 7, 3)]# Need to use tuple instead of list because of a bug related to nested list with Keras. https://datascience.stackexchange.com/questions/66341/cannot-clone-object-keras-wrappers-scikit-learn-kerasregressor-object-at-0x7fdc\n",
        "activation = ['tanh', 'relu']\n",
        "kernel_initializer = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "optimizer = ['Adam', 'Adamax', 'Nadam']\n",
        "batch_size = [16, 32, 64, 128, 256, 512, 1024]\n",
        "epochs=[50, 100, 150]\n",
        "param_grid = dict(layers=layers, activation=activation, kernel_initializer=kernel_initializer, optimizer=optimizer, batch_size = batch_size, epochs=epochs)\n",
        "param_grid"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['tanh', 'relu'],\n",
              " 'batch_size': [16, 32, 64, 128, 256, 512, 1024],\n",
              " 'epochs': [50, 100, 150],\n",
              " 'kernel_initializer': ['uniform',\n",
              "  'lecun_uniform',\n",
              "  'normal',\n",
              "  'zero',\n",
              "  'glorot_normal',\n",
              "  'glorot_uniform',\n",
              "  'he_normal',\n",
              "  'he_uniform'],\n",
              " 'layers': [30, (30, 15), (30, 15, 7), (30, 15, 7, 3)],\n",
              " 'optimizer': ['Adam', 'Adamax', 'Nadam']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaUjN31wGPnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e6d8de-9675-47be-c419-58abf6752b82"
      },
      "source": [
        "l = enumerate(layers)\n",
        "print(list(l))"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 30), (1, (30, 15)), (2, (30, 15, 7)), (3, (30, 15, 7, 3))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEm5dLg1GPi0"
      },
      "source": [
        "def create_model(layers, activation='relu', batch_size=32, epochs=50, kernel_initializer='normal', optimizer = 'adam'):\n",
        "    # Add seed later\n",
        "    model = Sequential()\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i==0:\n",
        "            model.add(Dense(nodes,kernel_initializer=kernel_initializer, input_dim=X_train.shape[1]))\n",
        "            model.add(Activation(activation))\n",
        "#             model.add(Dropout(dropout))\n",
        "        else:\n",
        "            model.add(Dense(nodes,kernel_initializer=kernel_initializer))\n",
        "            model.add(Activation(activation))\n",
        "#             model.add(Dropout(dropout))\n",
        "            \n",
        "    model.add(Dense(units = 1, activation = 'sigmoid')) # Note: no activation beyond this point\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcCVYovzdLM-"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jEyUTK0GPef"
      },
      "source": [
        "# Change function to estimator\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZVPO4GcWbd3"
      },
      "source": [
        "# Space\n",
        "space = {\n",
        "    'layers': hp.choice('layers', layers),\n",
        "    'activation': hp.choice('activation', activation),\n",
        "    'kernel_initializer': hp.choice('kernel_initializer', kernel_initializer),\n",
        "    'optimizer': hp.choice('optimizer', optimizer),    \n",
        "    'batch_size': hp.choice('batch_size', batch_size),    \n",
        "    'epochs': hp.choice('epochs', epochs),        \n",
        "#     'dropout': hp.choice('dropout', dropout)      \n",
        "#     'tol' : hp.uniform('tol', 0.00001, 1), #Tolerance for stopping criteria\n",
        "#     'C' : hp.uniform('C', 0.0001, 10000),\n",
        "#     'penalty': hp.choice('penalty',['l1', 'l2', 'none']),\n",
        "# #     'l1_ratio': hp.uniform('l1_ratio', 0, 1),\n",
        "#     'max_iter' : hp.choice('max_iter', range(5,1000)) #Maximum number of iterations taken for the solvers to converge\n",
        "}"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQrS0mLWbZQ"
      },
      "source": [
        "# Objective function\n",
        "def objective(params, n_folds = N_FOLDS):\n",
        "\n",
        "    # Perform n_fold cross validation with hyperparameters\n",
        "    # Use early stopping and evaluate based on ROC AUC\n",
        "    \n",
        "    model = KerasClassifier(build_fn=create_model, verbose=0,**params)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=n_folds, scoring='precision', n_jobs=-1)\n",
        "\n",
        "    # Extract the best score\n",
        "    best_score = max(scores)\n",
        "\n",
        "    # Loss must be minimized\n",
        "    loss = 1 - best_score\n",
        "\n",
        "    # Dictionary with information for evaluation\n",
        "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lELeApcuWbVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7da89b-e7dd-43f1-c933-ff138b0fc04e"
      },
      "source": [
        "# Algorithm\n",
        "tpe_algorithm = tpe.suggest\n",
        "\n",
        "# Trials object to track progress\n",
        "bayes_trials = Trials()\n",
        "\n",
        "# Optimize\n",
        "best = fmin(fn = objective, space = space, algo = tpe_algorithm, max_evals = MAX_EVALS, trials = bayes_trials)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:19<00:00,  9.54s/it, best loss: 0.011627906976744207]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfQztEREWbRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74926beb-f27a-42c5-868e-a7b0b041f13d"
      },
      "source": [
        "best"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 1,\n",
              " 'batch_size': 1,\n",
              " 'epochs': 2,\n",
              " 'kernel_initializer': 5,\n",
              " 'layers': 3,\n",
              " 'optimizer': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWY3hJEWbNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7d47c9-8fd5-4262-8c5e-2008ccf897b6"
      },
      "source": [
        "param_grid"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['tanh', 'relu'],\n",
              " 'batch_size': [16, 32, 64, 128, 256, 512, 1024],\n",
              " 'epochs': [50, 100, 150],\n",
              " 'kernel_initializer': ['uniform',\n",
              "  'lecun_uniform',\n",
              "  'normal',\n",
              "  'zero',\n",
              "  'glorot_normal',\n",
              "  'glorot_uniform',\n",
              "  'he_normal',\n",
              "  'he_uniform'],\n",
              " 'layers': [30, (30, 15), (30, 15, 7), (30, 15, 7, 3)],\n",
              " 'optimizer': ['Adam', 'Adamax', 'Nadam']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJaQrXwuf1L0"
      },
      "source": [
        "## Bayesian Optimization Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZec9eIZWbJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6518f41-3c69-446f-e74b-4304415dcf26"
      },
      "source": [
        "# Set seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "# tf.compat.v1.set_random_seed(0)\n",
        "# tf.random.set_random_seed(0)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "start = time.time()\n",
        "nn = Sequential()\n",
        "nn.add(Dense(30,input_dim=30,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(15,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(7,activation='tanh'))\n",
        "nn.add(Dropout(0.4))\n",
        "nn.add(Dense(1,kernel_initializer= 'glorot_normal', activation='sigmoid'))\n",
        "#init_weights = np.array(nn.get_weights()[0]).sum()\n",
        "nn.compile(loss='binary_crossentropy',optimizer='Adamax')   \n",
        "# nn.compile(optimizer=keras.optimizers.RMSprop(lr=1e-2),loss=keras.losses.MSE)\n",
        "nn.fit(X_train,y_train, epochs=50,batch_size=1024)\n",
        "end = time.time()\n",
        "fit_time = (end - start)\n",
        "print('fit time is: ', fit_time)\n",
        "start_time = time.time()\n",
        "y_test_predict = nn.predict_classes(X_test)\n",
        "end_time = time.time()\n",
        "predict_time = end_time - start_time\n",
        "print('predict time is: ', predict_time)\n",
        "y_test_predict.sum()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.8328\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8678\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8100\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7798\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7724\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7138\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7419\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6824\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7005\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6789\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6561\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6252\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6260\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6060\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6267\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6125\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5450\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5696\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5245\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5810\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5481\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5220\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4945\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4954\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5131\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5057\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5199\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5312\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4844\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4610\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4767\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4693\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5032\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4605\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4431\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4305\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4828\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4311\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4455\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4165\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4407\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4316\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3993\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4074\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3974\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4089\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4138\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4276\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4187\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3741\n",
            "fit time is:  1.1208388805389404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predict time is:  0.27158069610595703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lAwDBUCil09"
      },
      "source": [
        "## Neural Network Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1R2fNlMWbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4fe3b2-2d5d-456b-c090-f37011ee1eb5"
      },
      "source": [
        "y_test_prob = nn.predict_proba(X_test)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP0Yx4M8WbDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "2d672b17-d5c0-4466-e0bb-e1ba2547cfc0"
      },
      "source": [
        "testPred = X_test.copy()\n",
        "testPred['y_test'], testPred['y_test_prob'], testPred['y_test_predict']=[y_test,y_test_prob,y_test_predict]\n",
        "testPred.head()"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>radius error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_test_prob</th>\n",
              "      <th>y_test_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.221053</td>\n",
              "      <td>-0.355912</td>\n",
              "      <td>-0.231333</td>\n",
              "      <td>-0.161929</td>\n",
              "      <td>-0.079018</td>\n",
              "      <td>-0.491999</td>\n",
              "      <td>0.027651</td>\n",
              "      <td>-0.276232</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>0.132176</td>\n",
              "      <td>-0.448110</td>\n",
              "      <td>-0.470694</td>\n",
              "      <td>0.234114</td>\n",
              "      <td>0.413949</td>\n",
              "      <td>-0.160486</td>\n",
              "      <td>-0.182696</td>\n",
              "      <td>-0.032743</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.329612</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.356299</td>\n",
              "      <td>-0.104741</td>\n",
              "      <td>-0.199563</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>0.196958</td>\n",
              "      <td>-0.333935</td>\n",
              "      <td>-0.269040</td>\n",
              "      <td>0.448503</td>\n",
              "      <td>0.183204</td>\n",
              "      <td>-0.168905</td>\n",
              "      <td>1</td>\n",
              "      <td>0.840653</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.225780</td>\n",
              "      <td>-0.500666</td>\n",
              "      <td>0.308825</td>\n",
              "      <td>-0.305168</td>\n",
              "      <td>-0.793157</td>\n",
              "      <td>1.351264</td>\n",
              "      <td>-0.027309</td>\n",
              "      <td>0.789060</td>\n",
              "      <td>0.241064</td>\n",
              "      <td>-1.160679</td>\n",
              "      <td>1.302886</td>\n",
              "      <td>1.366877</td>\n",
              "      <td>-0.446227</td>\n",
              "      <td>-0.838325</td>\n",
              "      <td>0.470149</td>\n",
              "      <td>1.296951</td>\n",
              "      <td>1.384594</td>\n",
              "      <td>-0.865695</td>\n",
              "      <td>-0.809083</td>\n",
              "      <td>-0.760851</td>\n",
              "      <td>1.732277</td>\n",
              "      <td>-0.131459</td>\n",
              "      <td>0.978975</td>\n",
              "      <td>-0.016736</td>\n",
              "      <td>-1.000578</td>\n",
              "      <td>1.746605</td>\n",
              "      <td>1.779007</td>\n",
              "      <td>-0.572873</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.131049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.175418</td>\n",
              "      <td>-0.594561</td>\n",
              "      <td>-0.140496</td>\n",
              "      <td>-0.124794</td>\n",
              "      <td>-0.504551</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.340350</td>\n",
              "      <td>0.824140</td>\n",
              "      <td>0.725686</td>\n",
              "      <td>-0.685782</td>\n",
              "      <td>0.400820</td>\n",
              "      <td>0.378508</td>\n",
              "      <td>0.913744</td>\n",
              "      <td>0.435855</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>0.112838</td>\n",
              "      <td>0.249497</td>\n",
              "      <td>-0.267004</td>\n",
              "      <td>-0.795764</td>\n",
              "      <td>-0.781898</td>\n",
              "      <td>0.484159</td>\n",
              "      <td>-0.094562</td>\n",
              "      <td>0.560244</td>\n",
              "      <td>0.512911</td>\n",
              "      <td>-0.208132</td>\n",
              "      <td>0.525386</td>\n",
              "      <td>0.619345</td>\n",
              "      <td>0.974533</td>\n",
              "      <td>-0.103143</td>\n",
              "      <td>0.052562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.242376</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>-0.547998</td>\n",
              "      <td>0.417599</td>\n",
              "      <td>-0.020461</td>\n",
              "      <td>0.554262</td>\n",
              "      <td>0.835972</td>\n",
              "      <td>-0.532101</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>-0.539846</td>\n",
              "      <td>-0.142993</td>\n",
              "      <td>1.165609</td>\n",
              "      <td>-0.432457</td>\n",
              "      <td>-0.490575</td>\n",
              "      <td>0.643316</td>\n",
              "      <td>-0.002259</td>\n",
              "      <td>-0.374576</td>\n",
              "      <td>-0.327740</td>\n",
              "      <td>-0.824604</td>\n",
              "      <td>0.986380</td>\n",
              "      <td>0.160756</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>-0.641257</td>\n",
              "      <td>0.054930</td>\n",
              "      <td>-0.622863</td>\n",
              "      <td>-0.152986</td>\n",
              "      <td>0.534440</td>\n",
              "      <td>-0.525756</td>\n",
              "      <td>-0.701842</td>\n",
              "      <td>0.553709</td>\n",
              "      <td>-0.557739</td>\n",
              "      <td>-0.450625</td>\n",
              "      <td>1</td>\n",
              "      <td>0.847247</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>-0.428529</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.509965</td>\n",
              "      <td>0.783709</td>\n",
              "      <td>0.649494</td>\n",
              "      <td>-0.716683</td>\n",
              "      <td>0.145150</td>\n",
              "      <td>-0.592724</td>\n",
              "      <td>-0.269044</td>\n",
              "      <td>0.711976</td>\n",
              "      <td>-0.713374</td>\n",
              "      <td>-0.734828</td>\n",
              "      <td>0.247636</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-1.128546</td>\n",
              "      <td>-0.612877</td>\n",
              "      <td>-0.457547</td>\n",
              "      <td>1.703076</td>\n",
              "      <td>-0.259386</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>-0.743216</td>\n",
              "      <td>-0.270137</td>\n",
              "      <td>-0.691687</td>\n",
              "      <td>-0.443716</td>\n",
              "      <td>-0.144403</td>\n",
              "      <td>-0.848337</td>\n",
              "      <td>-0.830233</td>\n",
              "      <td>0.093432</td>\n",
              "      <td>-0.924975</td>\n",
              "      <td>-0.976611</td>\n",
              "      <td>1</td>\n",
              "      <td>0.860040</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area error  compactness error  ...  y_test_prob  y_test_predict\n",
              "204   -0.221053          -0.355912  ...     0.840653               1\n",
              "70     1.225780          -0.500666  ...     0.131049               0\n",
              "131    0.175418          -0.594561  ...     0.242376               0\n",
              "431   -0.547998           0.417599  ...     0.847247               1\n",
              "540   -0.428529           0.874216  ...     0.860040               1\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJrgrHjUi16E"
      },
      "source": [
        "## Neural Network Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv_m1KoWWa_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1deb36a9-dd69-47c5-e497-840471345145"
      },
      "source": [
        "#ROC/AUC Curve\n",
        "from sklearn import metrics\n",
        "# y_test_prob=et_gs.predict_proba(X_test)[:,1]\n",
        "fpr,tpr, _=metrics.roc_curve(y_test,y_test_prob)\n",
        "auc=metrics.roc_auc_score(y_test,y_test_prob)\n",
        "plt.plot(fpr,tpr,label=\"area=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SySLahQ0Wa7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a74c23-fc0c-4fc9-ce95-36a9cdd127e1"
      },
      "source": [
        "log_loss(y_test,y_test_prob)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20235608008347059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXE4jpJlWa2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdeae8e3-d7df-49bf-ba00-0f199f2adb97"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_test_predict)\n",
        "cmtx = pd.DataFrame(cm, index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes'])\n",
        "print(cmtx)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          pred:no  pred:yes\n",
            "true:no        39         4\n",
            "true:yes        1        70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gJWYLjlWaxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9362ca62-4bfd-4059-c003-ebd7a5730435"
      },
      "source": [
        "print(classification_report(y_test, y_test_predict))"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wNzI8GNjLRc"
      },
      "source": [
        "## Neural Network Model Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9NG5FTzWas6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "b631a109-1142-4b3e-ede9-567620ab244c"
      },
      "source": [
        "# Plot the predicted probability distribution\n",
        "sns.distplot(y_test_prob, label='Predicted Probability', kde=False)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92194fd190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN4klEQVR4nO3dfYxldX3H8fdHVkKLKCDjZsNDF+OKJTaAnfAQm1ZZaNA27CY1RNRmbTZuYlqj0T6s7T99+gPSVOsfpulGrJNGHhYq3Y1ttZsNhLSRrYOAFVbKQwGXAjtSqE+pFv32jzlbNrN39555uPfOj32/ksk959xz535zMvvO2TP33klVIUlqzysmPYAkaWkMuCQ1yoBLUqMMuCQ1yoBLUqPWjPPJzjjjjFq/fv04n1KSmnfPPfd8u6qmFm4fa8DXr1/P7OzsOJ9SkpqX5IlB272EIkmNMuCS1CgDLkmNGhrwJOclue+wr+8k+UiS05PsSfJwd3vaOAaWJM0bGvCqeqiqLqyqC4GfB34A3A5sB/ZW1QZgb7cuSRqTxV5C2Qg8WlVPAJuAmW77DLB5JQeTJB3bYgP+buCmbnltVT3dLT8DrB30gCTbkswmmZ2bm1vimJKkhXoHPMmJwNXArQvvq/nPpB34ubRVtaOqpqtqemrqiNehS5KWaDFn4O8AvlZVz3brzyZZB9DdHlzp4SRJR7eYd2Jey0uXTwB2A1uA67rbXSs4l6QlunHfk5MeQQu855JzRvJ9e52BJzkZuBL4wmGbrwOuTPIwcEW3Lkkak15n4FX1feC1C7Y9x/yrUiRJE+A7MSWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUb0CnuTUJLcl+WaS/UkuS3J6kj1JHu5uTxv1sJKkl/Q9A/8U8KWqehNwAbAf2A7sraoNwN5uXZI0JkMDnuQ1wC8CNwBU1Y+q6gVgEzDT7TYDbB7VkJKkI/U5Az8XmAP+Osm9ST6T5GRgbVU93e3zDLB20IOTbEsym2R2bm5uZaaWJPUK+BrgLcBfVtVFwPdZcLmkqgqoQQ+uqh1VNV1V01NTU8udV5LU6RPwA8CBqtrXrd/GfNCfTbIOoLs9OJoRJUmDDA14VT0DfCvJed2mjcCDwG5gS7dtC7BrJBNKkgZa03O/DwGfT3Ii8BjwG8zHf2eSrcATwDWjGVGSNEivgFfVfcD0gLs2ruw4kqS+fCemJDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDWq11+lT/I48F3gx8CLVTWd5HTgFmA98DhwTVU9P5oxJUkLLeYM/O1VdWFVTXfr24G9VbUB2NutS5LGZDmXUDYBM93yDLB5+eNIkvrqG/AC/inJPUm2ddvWVtXT3fIzwNpBD0yyLclsktm5ublljitJOqTXNXDgF6rqqSSvA/Yk+ebhd1ZVJalBD6yqHcAOgOnp6YH7SJIWr9cZeFU91d0eBG4HLgaeTbIOoLs9OKohJUlHGhrwJCcnOeXQMvDLwDeA3cCWbrctwK5RDSlJOlKfSyhrgduTHNr/xqr6UpKvAjuTbAWeAK4Z3ZiSpIWGBryqHgMuGLD9OWDjKIaSJA3nOzElqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVG9A57khCT3Jvlit35ukn1JHklyS5ITRzemJGmhxZyBfxjYf9j69cAnq+oNwPPA1pUcTJJ0bL0CnuQs4FeAz3TrAS4Hbut2mQE2j2JASdJgfc/A/wL4XeAn3fprgReq6sVu/QBw5qAHJtmWZDbJ7Nzc3LKGlSS9ZGjAk/wqcLCq7lnKE1TVjqqarqrpqamppXwLSdIAa3rs81bg6iTvBE4CXg18Cjg1yZruLPws4KnRjSlJWmhowKvq48DHAZK8DfjtqnpvkluBdwE3A1uAXSOckxv3PTnKb68leM8l50x6BOm4tpzXgf8e8NEkjzB/TfyGlRlJktRHn0so/6+q7gTu7JYfAy5e+ZEkSX34TkxJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJatTQgCc5Kcm/Jrk/yQNJ/qjbfm6SfUkeSXJLkhNHP64k6ZA+Z+A/BC6vqguAC4GrklwKXA98sqreADwPbB3dmJKkhYYGvOZ9r1t9ZfdVwOXAbd32GWDzSCaUJA3U6xp4khOS3AccBPYAjwIvVNWL3S4HgDOP8thtSWaTzM7Nza3EzJIkega8qn5cVRcCZwEXA2/q+wRVtaOqpqtqempqaoljSpIWWtSrUKrqBeAO4DLg1CRrurvOAp5a4dkkScfQ51UoU0lO7ZZ/CrgS2M98yN/V7bYF2DWqISVJR1ozfBfWATNJTmA++Dur6otJHgRuTvKnwL3ADSOcU5K0wNCAV9XXgYsGbH+M+evhkqQJ8J2YktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSooQFPcnaSO5I8mOSBJB/utp+eZE+Sh7vb00Y/riTpkD5n4C8CH6uq84FLgd9Mcj6wHdhbVRuAvd26JGlMhga8qp6uqq91y98F9gNnApuAmW63GWDzqIaUJB1pUdfAk6wHLgL2AWur6unurmeAtUd5zLYks0lm5+bmljGqJOlwvQOe5FXA3wIfqarvHH5fVRVQgx5XVTuqarqqpqemppY1rCTpJb0CnuSVzMf781X1hW7zs0nWdfevAw6OZkRJ0iB9XoUS4AZgf1V94rC7dgNbuuUtwK6VH0+SdDRreuzzVuDXgX9Lcl+37feB64CdSbYCTwDXjGZESdIgQwNeVf8M5Ch3b1zZcSRJfflOTElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElq1NCAJ/lskoNJvnHYttOT7EnycHd72mjHlCQt1OcM/HPAVQu2bQf2VtUGYG+3Lkkao6EBr6q7gP9asHkTMNMtzwCbV3guSdIQS70Gvraqnu6WnwHWHm3HJNuSzCaZnZubW+LTSZIWWvYvMauqgDrG/Tuqarqqpqemppb7dJKkzlID/mySdQDd7cGVG0mS1MdSA74b2NItbwF2rcw4kqS++ryM8CbgK8B5SQ4k2QpcB1yZ5GHgim5dkjRGa4btUFXXHuWujSs8iyRpEXwnpiQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqOGvoxQOpob9z056RGk45pn4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY1aVsCTXJXkoSSPJNm+UkNJkoZbcsCTnAB8GngHcD5wbZLzV2owSdKxLecM/GLgkap6rKp+BNwMbFqZsSRJwyznL/KcCXzrsPUDwCULd0qyDdjWrX4vyUPLeM4WnAF8e9JDrHIeo+E8RsM1c4zeu/xv8TODNo78T6pV1Q5gx6ifZ7VIMltV05OeYzXzGA3nMRrOY7S8SyhPAWcftn5Wt02SNAbLCfhXgQ1Jzk1yIvBuYPfKjCVJGmbJl1Cq6sUkvwV8GTgB+GxVPbBik7XruLlctAweo+E8RsMd98coVTXpGSRJS+A7MSWpUQZckhplwJdg2EcIJPlokgeTfD3J3iQDX8P5ctf3oxaS/FqSSnLcvSSszzFKck338/RAkhvHPeOk9fj3dk6SO5Lc2/2be+ck5pyIqvJrEV/M/8L2UeD1wInA/cD5C/Z5O/DT3fIHgVsmPfdqPE7dfqcAdwF3A9OTnnu1HSNgA3AvcFq3/rpJz70Kj9EO4IPd8vnA45Oee1xfnoEv3tCPEKiqO6rqB93q3cy/Rv540/ejFv4EuB74n3EOt0r0OUYfAD5dVc8DVNXBMc84aX2OUQGv7pZfA/znGOebKAO+eIM+QuDMY+y/FfjHkU60Og09TkneApxdVX8/zsFWkT4/S28E3pjkX5LcneSqsU23OvQ5Rn8IvC/JAeAfgA+NZ7TJG/lb6Y9nSd4HTAO/NOlZVpskrwA+Abx/wqOsdmuYv4zyNub/J3dXkp+rqhcmOtXqci3wuar68ySXAX+T5M1V9ZNJDzZqnoEvXq+PEEhyBfAHwNVV9cMxzbaaDDtOpwBvBu5M8jhwKbD7OPtFZp+fpQPA7qr636r6D+DfmQ/68aLPMdoK7ASoqq8AJzH/QVcvewZ88YZ+hECSi4C/Yj7ex9s1y0OOeZyq6r+r6oyqWl9V65n/XcHVVTU7mXEnos/HUfwd82ffJDmD+Usqj41zyAnrc4yeBDYCJPlZ5gM+N9YpJ8SAL1JVvQgc+giB/cDOqnogyR8nubrb7c+AVwG3JrkvyXH3GTE9j9Nxrecx+jLwXJIHgTuA36mq5yYz8fj1PEYfAz6Q5H7gJuD91b0k5eXOt9JLUqM8A5ekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRv0fQuhZAJg6ODYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sXYG0yyGPag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "16c5b8cd-4d99-494e-f0e1-291ea6f48425"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.kdeplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1');\n",
        "sns.kdeplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0');\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSNEyeCxji0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "74b5ba24-eeb5-42c4-e3cf-f923bbaa48c7"
      },
      "source": [
        "# this is to plot the kde by label\n",
        "sns.distplot(testPred[testPred['y_test']==1]['y_test_prob'],label='1', kde=False);\n",
        "sns.distplot(testPred[testPred['y_test']==0]['y_test_prob'],label='0', kde=False);\n",
        "\n",
        "# add labels\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASUElEQVR4nO3deZQlZX3G8e8DaARXyIzIQcZxwWUOIpIBMSqCW3DDLYpbgsQwatRo1BgOegKaY445RjGJRkVU1AhxRTEaUQk6YmQZENnUuAFBFIZFcSEg8Msft1rbtumunum6t3ve7+ecPl1Vt27V79bpfu5731v1VqoKSVI7tpp0AZKk8TL4JakxBr8kNcbgl6TGGPyS1JhtJl1AHytWrKjVq1dPugxJWlbOOuusK6tq5czlyyL4V69ezYYNGyZdhiQtK0kunm25XT2S1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSYZXHlriRtKY47/ZIFrf/sB61a9Bps8UtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ias+VfwLXhfcNsd+0hw2xXkgZmi1+SGmPwS1JjDH5JaozBL0mNMfglqTGDBX+SXZKckuTCJBckeVm3fIckX0jyne739kPVIEn6XUO2+G8EXllVa4B9gBcnWQMcBpxcVbsCJ3fzkqQxGSz4q+pHVXV2N/0z4JvAzsCTgPd3q70fePJQNUiSftdY+viTrAYeCJwO7FhVP+oe+jGw4zhqkCSNDH7lbpLbAR8HXl5V1yb59WNVVUnqFp63DlgHsGrV4t96TJIWw0JvpbgUDNriT3IrRqH/oar6RLf48iQ7dY/vBFwx23Or6uiqWltVa1euXDlkmZLUlCHP6gnwHuCbVfWWaQ+dCBzcTR8MfGqoGiRJv2vIrp6HAH8CnJfknG7Z4cAbgY8keT5wMfCMAWuQJM0wWPBX1alAbuHhRw61X0nS3LxyV5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1ZrDgT/LeJFckOX/asiOT/DDJOd3P44bavyRpdkO2+I8FDphl+VFVtUf389kB9y9JmsVgwV9V64Grh9q+JGnTTKKP/yVJzu26grafwP4lqWnjDv53APcE9gB+BLz5llZMsi7JhiQbNm7cOK76JGmLN9bgr6rLq+qmqroZeDew9xzrHl1Va6tq7cqVK8dXpCRt4cYa/El2mjb7FOD8W1pXkjSMbYbacJLjgf2AFUkuBY4A9kuyB1DARcALhtq/JGl2gwV/VT1rlsXvGWp/kqR+vHJXkhpj8EtSYwx+SWqMwS9JjekV/EnuP3QhkqTx6Nvi/9ckZyT5iyR3HLQiSdKgegV/VT0MeA6wC3BWkuOSPHrQyiRJg+jdx19V3wFeC/wN8HDgn5N8K8lThypOkrT4+vbx757kKOCbwCOAJ1bV/brpowasT5K0yPpeufsvwDHA4VV13dTCqrosyWsHqUySNIi+wf944LqqugkgyVbAbarql1X1wcGqkyQtur59/F8Etp02v123TJK0zPQN/ttU1c+nZrrp7YYpSZI0pL7B/4ske07NJPkD4Lo51pckLVF9+/hfDnw0yWVAgLsABw1WlSRpML2Cv6rOTHJf4D7dom9X1a+GK0uSNJSF3IhlL2B195w9k1BVHxikKknSYHoFf5IPAvcEzgFu6hYXYPBL0jLTt8W/FlhTVTVkMZKk4fU9q+d8Rl/oSpKWub4t/hXAhUnOAK6fWlhVBw5SlSRpMH2D/8ghi5AkjU/f0zm/nORuwK5V9cUk2wFbD1uaJGkIfYdlPhT4GPCubtHOwCeHKkqSNJy+X+6+GHgIcC38+qYsdx6qKEnScPoG//VVdcPUTJJtGJ3HL0laZvoG/5eTHA5s291r96PAp4crS5I0lL7BfxiwETgPeAHwWUb335UkLTN9z+q5GXh39yNJWsb6jtXzA2bp06+qeyx6RZKkQS1krJ4ptwGeDuyw+OVIkobWq4+/qq6a9vPDqnoroxuwS5KWmb5dPXtOm92K0SeAhYzlL0nLwnGnXzLpEgbXN7zfPG36RuAi4BmLXo0kaXB9z+rZf+hCJEnj0ber5xVzPV5Vb1mcciRJQ1vIWT17ASd2808EzgC+M0RRkqTh9A3+uwJ7VtXPAJIcCXymqp47VGGSpGH0HbJhR+CGafM3dMskSctM3xb/B4AzkpzQzT8ZeP9cT0jyXuAJwBVVtVu3bAfgw8BqujODquqahZctSdpUfS/gegNwCHBN93NIVf39PE87FjhgxrLDgJOralfg5G5ekjRGfbt6ALYDrq2qfwIuTXL3uVauqvXA1TMWP4nffFJ4P6NPDpKkMep7OucRjM7suQ/wPuBWwL8xuivXQuxYVT/qpn/MHN8TJFkHrANYtWrVAnczBhvet/jbXHvI4m9Tkmbo2+J/CnAg8AuAqroMuP3m7Liqijnu4lVVR1fV2qpau3Llys3ZlSRpmr7Bf8P0oE5y203c3+VJduq2sRNwxSZuR5K0ifoG/0eSvAu4U5JDgS+yaTdlORE4uJs+GPjUJmxDkrQZ5u3jTxJGp2DeF7iWUT//31bVF+Z53vHAfsCKJJcCRwBvZPQm8nzgYhzoTZLGbt7gr6pK8tmquj8wZ9jPeN6zbuGhR/bdhiRp8fXt6jk7yV6DViJJGou+V+4+CHhukosYndkTRh8Gdh+qMEnSMOYM/iSrquoS4I/GVI8kaWDztfg/yWhUzouTfLyqnjaOoiRJw5mvjz/Tpu8xZCGSpPGYL/jrFqYlScvUfF09D0hyLaOW/7bdNPzmy907DFqdJGnRzRn8VbX1uAqRJI3HQoZlliRtAQx+SWqMwS9JjTH4JakxfYdskKRl67jTL5l0CUuKLX5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5Jasw2k9hpkouAnwE3ATdW1dpJ1CFJLZpI8Hf2r6orJ7h/SWqSXT2S1JhJBX8Bn09yVpJ1s62QZF2SDUk2bNy4cczlSdKWa1LB/9Cq2hN4LPDiJPvOXKGqjq6qtVW1duXKleOvUJK2UBMJ/qr6Yff7CuAEYO9J1CFJLRp78Ce5bZLbT00DjwHOH3cdktSqSZzVsyNwQpKp/R9XVZ+bQB2S1KSxB39VfR94wLj3K0ka8XROSWqMwS9JjTH4JakxkxyyQTNteN8w2117yDDblSbkuNMvmXQJy5otfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaoxX7rZgiCuCvRpYWrZs8UtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia4wVc0qZa5hfGLfT2hc9+0KqBKtG42eKXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcYLuLRpFvnipdN/cDUA31v19HnX3aIvJNrM4zp1HPu450I3vvUOv7tsjgvOFnqBmMbHFr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqzESCP8kBSb6d5LtJDptEDZLUqrEHf5KtgbcDjwXWAM9KsmbcdUhSqybR4t8b+G5Vfb+qbgD+HXjSBOqQpCZN4srdnYH/nTZ/KfCgmSslWQes62Z/nuTbY6htklYAV066iMl71VwPrgCufM6YKlmmxvx39Gfj29XiWVb/a5v593632RYu2SEbqupo4OhJ1zEuSTZU1dpJ17GUeYzm5zGan8doMl09PwR2mTZ/126ZJGkMJhH8ZwK7Jrl7klsDzwROnEAdktSksXf1VNWNSV4CnARsDby3qi4Ydx1LUDPdWpvBYzQ/j9H8mj9GqapJ1yBJGiOv3JWkxhj8ktQYg3/M5huuIskrklyY5NwkJyeZ9TzcLVnfIT2SPC1JJWnu1Lw+xyjJM7q/pQuSHDfuGietx//aqiSnJPl69//2uEnUORFV5c+Yfhh9mf094B7ArYFvAGtmrLM/sF03/SLgw5Oue6kdo2692wPrgdOAtZOue6kdI2BX4OvA9t38nSdd9xI8RkcDL+qm1wAXTbrucf3Y4h+veYerqKpTquqX3expjK5zaEnfIT3+DvgH4P/GWdwS0ecYHQq8vaquAaiqK8Zc46T1OUYF3KGbviNw2RjrmyiDf7xmG65i5znWfz7wn4NWtPTMe4yS7AnsUlWfGWdhS0ifv6N7A/dO8tUkpyU5YGzVLQ19jtGRwHOTXAp8FnjpeEqbvCU7ZEPrkjwXWAs8fNK1LCVJtgLeAjxvwqUsddsw6u7Zj9GnxvVJ7l9VP5loVUvLs4Bjq+rNSR4MfDDJblV186QLG5ot/vHqNVxFkkcBrwEOrKrrx1TbUjHfMbo9sBvwpSQXAfsAJzb2BW+fv6NLgROr6ldV9QPgfxi9EbSizzF6PvARgKr6GnAbRgO4bfEM/vGad7iKJA8E3sUo9Fvrl4V5jlFV/bSqVlTV6qpazeh7kAOrasNkyp2IPsOefJJRa58kKxh1/Xx/nEVOWJ9jdAnwSIAk92MU/BvHWuWEGPxjVFU3AlPDVXwT+EhVXZDk9UkO7FZ7E3A74KNJzknS1DhGPY9R03oeo5OAq5JcCJwC/HVVXTWZisev5zF6JXBokm8AxwPPq+4Uny2dQzZIUmNs8UtSYwx+SWqMwS9JjTH4JakxBr8kNcbg10Qkuak7XfX8JB9Nst1mbOvYJH/cTR+TZM0c6+6X5A83YR8XdefDz7b8vG50x88nucsCtrlfkv9YpDpemORPu+lZj0eSwxeyL225DH5NynVVtUdV7QbcALxw+oNJNmk4kar686q6cI5V9gMWHPzz2L+qdgc2AL8VrhkZ/P+sqt5ZVR+YZfn042HwCzD4tTR8BbhX1wL+SnfR2oVJtk7ypiRndi3qF8Cvw/Rt3VjrXwTuPLWhJF+aGr6hG4/97CTf6O5tsJrRG8xfdZ82HpZkZZKPd/s4M8lDuuf+fteCvyDJMUB6vI713etY3dX2AeB8YJfudZzffTo4aNpz7pDkM93675x6k0jyjiQbuv2/bsZ+Xt1t54wk9+rWPzLJq2YWNHU8krwR2LZ73R/qLmR6+bT13pDkZT1eo7YADtKmiepa9o8FPtct2hPYrap+kGQd8NOq2ivJ7wFfTfJ54IHAfRiNob4jcCHw3hnbXQm8G9i329YOVXV1kncCP6+qf+zWOw44qqpOTbKK0ZWe9wOOAE6tqtcneTyjcV3m8wTgvG56V+DgqjotydOAPYAHMBoL5swk67v19u5ex8XdMXgq8DHgNV29WwMnJ9m9qs7tnvPTqrp/17Xz1m6/c6qqw5K8pKr26F73auATwFu7N5tndrWoAQa/JmXbJOd0018B3sOoC+aMblAxgMcAu0/1VzMaM31XYF/g+Kq6CbgsyX/Nsv19gPVT26qqq2+hjkcBa5JfN+jvkOR23T6e2j33M0mumeO1nJLkJuBc4LXAnYCLq+q07vGHTqv38iRfBvYCru1e7/cBkhzfrfsx4BndG982wE6M3hymgv/4ab+PmqOuW1RVFyW5KqOxoXYEvt7SkA6tM/g1KddNtT6ndOH7i+mLgJdW1Ukz1lvMW+RtBexTVb91Q5dpbwR97F9VV0577p347dcxl5ljplSSuwOvAvaqqmuSHMtoALHZnrM5Y64cw2h467sw4xOTtmz28WspOwl4UZJbASS5d5LbMupLP6j7DmAnRrernOk0YN8uREmyQ7f8Z4yGdp7yeabdgCPJ1JvReuDZ3bLHAttvxuv4yrR6VzL6NHFG99jeGY0guRVwEHAqo7tC/QL4aZIdGXWFTXfQtN9fW0Adv5o6lp0TgAMYffo4afanaEtki19L2THAauDsjJrgG4EnMwqsRzDq27+EWcKvqjZ2XSWf6EL1CuDRwKeBjyV5EqPA/0vg7UnOZfT/sJ7RF8CvA45PcgHw391+NtUJwIMZ3fe1gFdX1Y+T3JfR8MFvA+7FaBTNE6rq5iRfB77F6C5SX52xve27eq9ndDORvo4Gzk1ydlU9p6puSHIK8JOuG0qNcHROqVHdG+LZwNOr6juTrkfjY1eP1KCMLur6LnCyod8eW/yS1Bhb/JLUGINfkhpj8EtSYwx+SWqMwS9Jjfl/hZfValprRzgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}